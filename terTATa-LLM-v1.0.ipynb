{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340ec1c8",
   "metadata": {},
   "source": [
    "# 🤖 TAT-LLM: From Tables and Text to Strategic Business Actions\n",
    "\n",
    "### Empowering Small and Medium-Sized Enterprises (SMSEs) with Decision Intelligence\n",
    "\n",
    "This project presents **TAT-LLM**, a Language Model system capable of answering complex business questions by understanding and reasoning over tabular data and accompanying text, such as financial reports, annual disclosures, or transaction summaries.\n",
    "\n",
    "## Technical Foundation\n",
    "\n",
    "- Dataset: [TAT-QA](https://huggingface.co/datasets/next-tat/TAT-QA)\n",
    "- Model: [Nous Hermes 2 Mistral 7B-DPO](https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO)\n",
    "- Prompt Style: 6-Step Instruction Reasoning\n",
    "- Evaluation: Exact Match (EM) and F1 across question types\n",
    "\n",
    "## Team Members\n",
    "- **Bima Aristo**\n",
    "- **Muhammad Fadli**\n",
    "- **Rifqi Aditya**\n",
    "\n",
    "We believe that decision-quality AI shouldn’t be exclusive to big corporations.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320107e",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f9fcc901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch import float16\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from evaluate import load as load_metric\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    PeftModel,\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae214a77",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01184909",
   "metadata": {},
   "source": [
    "### Check data pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8de60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.json: 13215 QA pairs\n",
      "dev.json: 1668 QA pairs\n",
      "test.json: 1669 QA pairs\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data\"\n",
    "json_files = [\"train.json\", \"dev.json\", \"test.json\"]\n",
    "\n",
    "for filename in json_files:\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_qa_pairs = sum(len(passage[\"questions\"]) for passage in data)\n",
    "    print(f\"{filename}: {total_qa_pairs} QA pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d0631",
   "metadata": {},
   "source": [
    "### Build train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51f61e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QA pairs: 13215\n",
      "{'question': 'What does the Weighted average actuarial assumptions consist of?', 'answer': \"['Rate of inflation', 'Rate of increase in salaries', 'Discount rate']\", 'answer_type': 'multi-span', 'answer_from': 'table', 'rel_paragraphs': '[]', 'req_comparison': False, 'table': \"{'uid': 'e78f8b29-6085-43de-b32f-be1a68641be3', 'table': [['', '2019 %', '2018 %', '2017 %'], ['Weighted average actuarial assumptions used at 31 March1:', '', '', ''], ['Rate of inflation2', '2.9', '2.9', '3.0'], ['Rate of increase in salaries', '2.7', '2.7', '2.6'], ['Discount rate', '2.3', '2.5', '2.6']]}\", 'paragraphs': \"[{'uid': '62be4f5a-1693-4e6b-8bb4-0a4e1e40b409', 'order': 1, 'text': 'Actuarial assumptions'}, {'uid': 'c63e6ed5-8fe5-46e4-a02a-f923e90e8067', 'order': 2, 'text': 'The Group’s scheme liabilities are measured using the projected unit credit method using the principal actuarial assumptions set out below:'}, {'uid': 'b4093fd4-43ea-4b31-9975-13c0012a0b18', 'order': 3, 'text': 'Notes: 1 Figures shown represent a weighted average assumption of the individual schemes.'}, {'uid': '9f6ecb32-9e2c-4036-8209-8905855145c0', 'order': 4, 'text': '2 The rate of increases in pensions in payment and deferred revaluation are dependent on the rate of inflation.'}]\"}\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "flattened = []  # flatten each question-answer pair as one record\n",
    "for entry in raw_data:\n",
    "    table = entry.get(\"table\", {})\n",
    "    paragraphs = entry.get(\"paragraphs\", [])\n",
    "    for q in entry.get(\"questions\", []):\n",
    "        flattened.append({\n",
    "            \"question\": str(q.get(\"question\", \"\")),\n",
    "            \"answer\": str(q.get(\"answer\", \"\")), # convert list or number to string\n",
    "            \"answer_type\": str(q.get(\"answer_type\", \"\")),\n",
    "            \"answer_from\": str(q.get(\"answer_from\", \"\")),\n",
    "            \"rel_paragraphs\": str(q.get(\"rel_paragraphs\", [])), # make sure it's string\n",
    "            \"req_comparison\": bool(q.get(\"req_comparison\", False)),\n",
    "            \"table\": str(table),    # avoid raw dicts/lists\n",
    "            \"paragraphs\": str(paragraphs),  # avoid raw lists\n",
    "        })\n",
    "\n",
    "\n",
    "train_data = Dataset.from_list(flattened)\n",
    "\n",
    "print(\"Number of QA pairs:\", len(train_data))\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9edf8fe",
   "metadata": {},
   "source": [
    "### Build test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7f5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test QA pairs: 1669\n",
      "{'question': 'What was the amount of unrecognized stock-based compensation expense related to unvested employee stock options in 2019?', 'answer': '', 'answer_type': '', 'answer_from': '', 'rel_paragraphs': '[]', 'req_comparison': False, 'table': \"{'uid': 'c4b92833-5c85-4bf4-b493-bc7741d759df', 'table': [['', 'Year Ended', 'Year Ended'], ['Stock-Based Compensation by Type of Award', 'December 31, 2019', 'December 31, 2018'], ['Stock options', '$2,756', '$2,926'], ['RSUs', '955', '1,129'], ['Total stock-based compensation expense', '$3,711', '$4,055']]}\", 'paragraphs': \"[{'uid': '04bfbe1d-235b-4036-95c2-e49983eb9cef', 'order': 1, 'text': 'Stock-based compensation expense is included in general and administrative expense for each period as follows:'}, {'uid': '0b5304d0-849b-46ea-936a-2b9d73be07f3', 'order': 2, 'text': 'As of December 31, 2019, there was $4,801 of unrecognized stock-based compensation expense related to unvested employee stock options and $1,882 of unrecognized stock-based compensation expense related to unvested RSUs. These costs are expected to be recognized over a weighted-average period of 2.13 and 2.33 years, respectively.'}]\"}\n"
     ]
    }
   ],
   "source": [
    "def flatten_qa_data(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    flattened = []\n",
    "    for entry in raw_data:\n",
    "        table = entry.get(\"table\", {})\n",
    "        paragraphs = entry.get(\"paragraphs\", [])\n",
    "        for q in entry.get(\"questions\", []):\n",
    "            flattened.append({\n",
    "                \"question\": str(q.get(\"question\", \"\")),\n",
    "                \"answer\": str(q.get(\"answer\", \"\")),\n",
    "                \"answer_type\": str(q.get(\"answer_type\", \"\")),\n",
    "                \"answer_from\": str(q.get(\"answer_from\", \"\")),\n",
    "                \"rel_paragraphs\": str(q.get(\"rel_paragraphs\", [])),\n",
    "                \"req_comparison\": bool(q.get(\"req_comparison\", False)),\n",
    "                \"table\": str(table),\n",
    "                \"paragraphs\": str(paragraphs),\n",
    "            })\n",
    "    return Dataset.from_list(flattened)\n",
    "\n",
    "test_data = flatten_qa_data(\"data/test.json\")\n",
    "print(\"Number of test QA pairs:\", len(test_data))\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba1e36",
   "metadata": {},
   "source": [
    "### Build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cdd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(table, paragraphs, question_dict, return_prompt_only=False):\n",
    "    table_md = \"\\n\".join([\"| \" + \" | \".join(row) + \" |\" for row in table[\"table\"]]) # table to markdown\n",
    "    text_content = \"\\n\".join([p[\"text\"] for p in paragraphs])   # text paragraph\n",
    "\n",
    "    question = question_dict.get(\"question\", \"\")\n",
    "    answer_type = question_dict.get(\"answer_type\", \"\")\n",
    "    gold_answer = question_dict.get(\"answer\", \"\")\n",
    "    gold_equation = question_dict.get(\"derivation\", \"N.A.\") or \"N.A.\"\n",
    "    scale = question_dict.get(\"scale\", \"none\") or \"none\"\n",
    "    \n",
    "    if answer_type == \"arithmetic\":\n",
    "        question_type = \"Arithmetic\"\n",
    "    elif answer_type == \"counting\":\n",
    "        question_type = \"Count\"\n",
    "    elif answer_type == \"multi-span\":\n",
    "        question_type = \"Multiple spans\"\n",
    "    else:\n",
    "        question_type = \"Single span\"\n",
    "    \n",
    "    if isinstance(gold_answer, list):\n",
    "        answer = \"#\".join(str(a) for a in gold_answer)\n",
    "    else:\n",
    "        answer = str(gold_answer)\n",
    "\n",
    "    if question_type != \"Arithmetic\":\n",
    "        gold_equation = \"N.A.\"\n",
    "\n",
    "    evidence = \"[evidence goes here manually if available, e.g., numbers or key phrases]\"\n",
    "    action = \"[action goes here — generate a short, logical recommendation based on the answer]\"\n",
    "\n",
    "    reasoning_steps = f\"\"\"Please organize the results in the following markdown table:\n",
    "| step | output |\n",
    "| 1 | {question_type} |\n",
    "| 2 | {evidence} |\n",
    "| 3 | {gold_equation} |\n",
    "| 4 | {answer} |\n",
    "| 5 | {scale} |\n",
    "| 6 | {action} |\"\"\" if not return_prompt_only else \"\"\n",
    "\n",
    "    final_answer_section = f\"\"\"\n",
    "The answer is: {answer} ####\n",
    "\"\"\" if not return_prompt_only else \"\"\n",
    "\n",
    "    prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer’s scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`.\n",
    "\n",
    "{reasoning_steps}\n",
    "{final_answer_section}\n",
    "\n",
    "### Table\n",
    "{table_md}\n",
    "\n",
    "### Text\n",
    "{text_content}\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e262e",
   "metadata": {},
   "source": [
    "### Create generate action & response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f908499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_action(answer, question_type, question):\n",
    "    \"\"\"Generate business insight/recommendation based on answer\"\"\"\n",
    "    if question_type == \"Arithmetic\":\n",
    "        if isinstance(answer, (int, float)):\n",
    "            if answer > 0:\n",
    "                return \"Consider strategies to maintain or accelerate this positive trend\"\n",
    "            elif answer < 0:\n",
    "                return \"Investigate root causes and develop mitigation strategies\"\n",
    "            else:\n",
    "                return \"Monitor for changes and prepare contingency plans\"\n",
    "    elif question_type == \"Count\":\n",
    "        return f\"Review if {answer} items meet target thresholds\"\n",
    "    else:\n",
    "        return \"Further analysis recommended based on this finding\"\n",
    "\n",
    "def generate_training_response(question_dict, table, paragraphs):\n",
    "    \"\"\"Generate the response part for training data\"\"\"\n",
    "    \n",
    "    # Extract evidence from derivation\n",
    "    derivation = question_dict.get(\"derivation\", \"\")\n",
    "    evidence_numbers = re.findall(r'\\d+\\.?\\d*', derivation)\n",
    "    evidence = \"#\".join(evidence_numbers) if evidence_numbers else \"\"\n",
    "    \n",
    "    # If no derivation, try to extract from answer and rel_paragraphs\n",
    "    if not evidence and question_dict.get(\"answer_from\") in [\"table\", \"text\", \"table-text\"]:\n",
    "        # This is a span-type question, use the answer itself as evidence\n",
    "        answer = question_dict.get(\"answer\", \"\")\n",
    "        if isinstance(answer, list):\n",
    "            evidence = \"#\".join(str(a) for a in answer)\n",
    "        else:\n",
    "            evidence = str(answer)\n",
    "\n",
    "    answer_type = question_dict.get(\"answer_type\", \"\")\n",
    "    if answer_type == \"arithmetic\":\n",
    "        question_type = \"Arithmetic\"\n",
    "    elif answer_type == \"counting\":\n",
    "        question_type = \"Count\"\n",
    "    elif answer_type == \"spans\":\n",
    "        question_type = \"Multiple spans\"\n",
    "    else:\n",
    "        question_type = \"Single span\"\n",
    "    \n",
    "    equation = derivation if answer_type == \"arithmetic\" else \"N.A.\"\n",
    "\n",
    "    answer = question_dict.get(\"answer\", \"\")\n",
    "    if isinstance(answer, list):\n",
    "        answer_str = \"#\".join(str(a) for a in answer)\n",
    "    else:\n",
    "        answer_str = str(answer)\n",
    "\n",
    "    scale = question_dict.get(\"scale\", \"none\") or \"none\"\n",
    "\n",
    "    action = generate_action(answer, question_type, question_dict.get(\"question\", \"\"))\n",
    "    \n",
    "    return {\n",
    "        \"question_type\": question_type,\n",
    "        \"evidence\": evidence,\n",
    "        \"equation\": equation,\n",
    "        \"answer\": answer_str,\n",
    "        \"scale\": scale,\n",
    "        \"action\": action\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6235a4",
   "metadata": {},
   "source": [
    "### Create prompt with response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1528257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction\n",
      "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
      "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{question_type}`.\n",
      "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{evidence}`.\n",
      "3. Step 3: If `{question_type}` is `Arithmetic`, generate an equation in `{equation}`. Otherwise, put `N.A.`.\n",
      "4. Step 4: Compute the final answer and store in `{answer}`.\n",
      "5. Step 5: Predict the answer’s scale in `{scale}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
      "6. Step 6: Based on the `{answer}` and `{question_type}`, generate a short and logical recommendation, business insight, or next action. Store it in `{action}`.\n",
      "\n",
      "Please organize the results in the following markdown table:\n",
      "| step | output |\n",
      "| 1 | Multiple spans |\n",
      "| 2 | [evidence goes here manually if available, e.g., numbers or key phrases] |\n",
      "| 3 | N.A. |\n",
      "| 4 | Rate of inflation#Rate of increase in salaries#Discount rate |\n",
      "| 5 | none |\n",
      "| 6 | [action goes here — generate a short, logical recommendation based on the answer] |\n",
      "\n",
      "The answer is: Rate of inflation#Rate of increase in salaries#Discount rate ####\n",
      "\n",
      "\n",
      "### Table\n",
      "|  | 2019 % | 2018 % | 2017 % |\n",
      "| Weighted average actuarial assumptions used at 31 March1: |  |  |  |\n",
      "| Rate of inflation2 | 2.9 | 2.9 | 3.0 |\n",
      "| Rate of increase in salaries | 2.7 | 2.7 | 2.6 |\n",
      "| Discount rate | 2.3 | 2.5 | 2.6 |\n",
      "\n",
      "### Text\n",
      "Actuarial assumptions\n",
      "The Group’s scheme liabilities are measured using the projected unit credit method using the principal actuarial assumptions set out below:\n",
      "Notes: 1 Figures shown represent a weighted average assumption of the individual schemes.\n",
      "2 The rate of increases in pensions in payment and deferred revaluation are dependent on the rate of inflation.\n",
      "\n",
      "### Question\n",
      "What does the Weighted average actuarial assumptions consist of?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the training response data\n",
    "response_data = generate_training_response(\n",
    "    question_dict={\n",
    "        \"question\": train_data[0][\"question\"],\n",
    "        \"answer\": ast.literal_eval(train_data[0][\"answer\"]),\n",
    "        \"answer_type\": train_data[0][\"answer_type\"],\n",
    "        \"answer_from\": train_data[0][\"answer_from\"],\n",
    "        \"derivation\": \"44.1-56.7\",\n",
    "        \"scale\": train_data[0].get(\"scale\", \"none\")\n",
    "    },\n",
    "    table=ast.literal_eval(train_data[0][\"table\"]),\n",
    "    paragraphs=ast.literal_eval(train_data[0][\"paragraphs\"])\n",
    ")\n",
    "\n",
    "# Create the prompt with the generated response\n",
    "prompt_output = create_prompt(\n",
    "    table=ast.literal_eval(train_data[0][\"table\"]),\n",
    "    paragraphs=ast.literal_eval(train_data[0][\"paragraphs\"]),\n",
    "    question_dict={\n",
    "        \"question\": train_data[0][\"question\"],\n",
    "        \"answer\": response_data[\"answer\"],\n",
    "        \"answer_type\": train_data[0][\"answer_type\"],\n",
    "        \"answer_from\": train_data[0][\"answer_from\"],\n",
    "        \"derivation\": response_data[\"equation\"],\n",
    "        \"scale\": response_data[\"scale\"],\n",
    "        \"action\": response_data[\"action\"]\n",
    "    }\n",
    ")\n",
    "print(prompt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96e796",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b247f4",
   "metadata": {},
   "source": [
    "### Set bitbytesands config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191b9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80287c3",
   "metadata": {},
   "source": [
    "### Tokenize LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc5b4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
    "    device_map='auto',\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=float16,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.model_max_length = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322f11f",
   "metadata": {},
   "source": [
    "### Create generate & tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c43d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return value    # just return as-is string if not evaluable\n",
    "\n",
    "def generate_and_tokenize_prompt(example):\n",
    "    table = safe_eval(example[\"table\"])\n",
    "    paragraphs = safe_eval(example[\"paragraphs\"])\n",
    "    answer = safe_eval(example[\"answer\"])\n",
    "\n",
    "    question_dict = {\n",
    "        \"question\": example[\"question\"],\n",
    "        \"answer\": answer,\n",
    "        \"answer_type\": example.get(\"answer_type\", \"\"),\n",
    "        \"answer_from\": example.get(\"answer_from\", \"\"),\n",
    "        \"derivation\": example.get(\"derivation\", \"N.A.\"),\n",
    "        \"scale\": example.get(\"scale\", \"none\"),\n",
    "        \"action\": example.get(\"action\", \"[action goes here...]\")\n",
    "    }\n",
    "\n",
    "    full_prompt = create_prompt(table, paragraphs, question_dict)\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        full_prompt,\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a34e38",
   "metadata": {},
   "source": [
    "### Mapping tokenization train & test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89808983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/13215 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 13215/13215 [00:20<00:00, 642.81 examples/s]\n",
      "Map: 100%|██████████| 1669/1669 [00:02<00:00, 669.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_data.map(generate_and_tokenize_prompt, remove_columns=train_data.column_names)\n",
    "tokenized_test_dataset = test_data.map(generate_and_tokenize_prompt, remove_columns=test_data.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd90e3",
   "metadata": {},
   "source": [
    "### Set LoRA config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc69a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16c52d",
   "metadata": {},
   "source": [
    "### Print model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d10787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 27262976 || all params: 3779350528 || trainable%: 0.7214\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.4f}\"\n",
    "    )\n",
    "    \n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4a90acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(model: Union[str, torch.nn.modules.module.Module, transformers.modeling_utils.PreTrainedModel], args: Union[trl.trainer.sft_config.SFTConfig, transformers.training_args.TrainingArguments, NoneType] = None, data_collator: Optional[transformers.data.data_collator.DataCollator] = None, train_dataset: Union[datasets.arrow_dataset.Dataset, datasets.iterable_dataset.IterableDataset, NoneType] = None, eval_dataset: Union[datasets.arrow_dataset.Dataset, dict[str, datasets.arrow_dataset.Dataset], NoneType] = None, processing_class: Union[transformers.tokenization_utils_base.PreTrainedTokenizerBase, transformers.image_processing_utils.BaseImageProcessor, transformers.feature_extraction_utils.FeatureExtractionMixin, transformers.processing_utils.ProcessorMixin, NoneType] = None, compute_loss_func: Optional[Callable] = None, compute_metrics: Optional[Callable[[transformers.trainer_utils.EvalPrediction], dict]] = None, callbacks: Optional[list[transformers.trainer_callback.TrainerCallback]] = None, optimizers: tuple[typing.Optional[torch.optim.optimizer.Optimizer], typing.Optional[torch.optim.lr_scheduler.LambdaLR]] = (None, None), optimizer_cls_and_kwargs: Optional[tuple[type[torch.optim.optimizer.Optimizer], dict[str, Any]]] = None, preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, peft_config: Optional[ForwardRef('PeftConfig')] = None, formatting_func: Optional[Callable[[dict], str]] = None)\n"
     ]
    }
   ],
   "source": [
    "from inspect import signature\n",
    "print(signature(SFTTrainer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5da2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLossCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None:\n",
    "            return\n",
    "        \n",
    "        if 'loss' in logs:\n",
    "            print(f\"Step {state.global_step} | Loss: {logs['loss']:.4f} | LR: {logs.get('learning_rate', 'N/A')}\")\n",
    "        \n",
    "        if 'eval_loss' in logs:\n",
    "            print(f\"[Eval] Step {state.global_step} | Eval Loss: {logs['eval_loss']:.4f}\")\n",
    "        \n",
    "        if 'exact_match' in logs or 'f1' in logs:\n",
    "            em = logs.get('exact_match', 'N/A')\n",
    "            f1 = logs.get('f1', 'N/A')\n",
    "            print(f\"[Eval] Step {state.global_step} | EM: {em:.2f} | F1: {f1:.2f}\")\n",
    "        \n",
    "        if 'loss' not in logs and 'eval_loss' not in logs and len(logs) > 0:\n",
    "            print(f\"Step {state.global_step} | Available metrics: {', '.join(logs.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c186514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except:\n",
    "        return value\n",
    "\n",
    "def formatting_func(example):\n",
    "    table = safe_eval(example[\"table\"])\n",
    "    paragraphs = safe_eval(example[\"paragraphs\"])\n",
    "    answer = safe_eval(example[\"answer\"])\n",
    "    \n",
    "    question_dict = {\n",
    "        \"question\": example[\"question\"],\n",
    "        \"answer\": answer,\n",
    "        \"answer_type\": example.get(\"answer_type\", \"\"),\n",
    "        \"answer_from\": example.get(\"answer_from\", \"\"),\n",
    "        \"derivation\": example.get(\"derivation\", \"N.A.\"),\n",
    "        \"scale\": example.get(\"scale\", \"none\")\n",
    "    }\n",
    "\n",
    "    return create_prompt(table, paragraphs, question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bb448699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    import re\n",
    "    import string\n",
    "    text = text.lower()\n",
    "    text = ''.join(ch for ch in text if ch not in string.punctuation)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def normalize_textv2(s):\n",
    "    import re\n",
    "    import string\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\b(a|an|the)\\b\", \" \", s)   # removes 'a', 'an', 'the'\n",
    "    s = \"\".join(ch for ch in s if ch not in string.punctuation)\n",
    "    s = \" \".join(s.split()) # normalize all whitespace to single spaces\n",
    "    return s\n",
    "\n",
    "def compute_exact(a_pred, a_gold):\n",
    "    return int(normalize_textv2(a_pred) == normalize_textv2(a_gold))\n",
    "\n",
    "def compute_f1(a_pred, a_gold):\n",
    "    pred_tokens = normalize_text(a_pred).split()\n",
    "    gold_tokens = normalize_text(a_gold).split()\n",
    "    common = set(pred_tokens) & set(gold_tokens)\n",
    "    if len(common) == 0:\n",
    "        return 0.0\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(gold_tokens)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    # Fix for nested list of predictions\n",
    "    try:\n",
    "        predictions = np.array(pred.predictions)\n",
    "        if predictions.ndim == 3:\n",
    "            predictions = np.argmax(predictions, axis=-1)   # predictions are logits -> take argmax first\n",
    "        elif predictions.ndim == 1:\n",
    "            predictions = [predictions.tolist()]    # sometimes it's already flattened\n",
    "    except Exception as e:\n",
    "        print(\"Prediction format error:\", e)\n",
    "        predictions = pred.predictions\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    label_ids = []  # handle -100s in label_ids\n",
    "    for label in pred.label_ids:\n",
    "        label = np.array(label)\n",
    "        label = label[label != -100]\n",
    "        label_ids.append(label)\n",
    "\n",
    "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    em_scores = []\n",
    "    f1_scores = []\n",
    "    for pred_str, label_str in zip(decoded_preds, decoded_labels):\n",
    "        em = compute_exact(pred_str, label_str)\n",
    "        f1 = compute_f1(pred_str, label_str)\n",
    "        em_scores.append(em)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        \"exact_match\": np.mean(em_scores) * 100,\n",
    "        \"f1\": np.mean(f1_scores) * 100\n",
    "    }\n",
    "\n",
    "def compute_metricsv2(pred):\n",
    "    preds = pred.predictions\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    pred_ids = np.argmax(preds, axis=-1)    # convert logits to IDs\n",
    "    predictions = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Clean -100 from labels\n",
    "    label_ids = [label[label != -100] if hasattr(label, \"__getitem__\") else label for label in pred.label_ids]\n",
    "    labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    em_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for p, g in zip(predictions, labels):\n",
    "        em = compute_exact(p, g)\n",
    "        f1 = compute_f1(p, g)\n",
    "        em_scores.append(em)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        \"exact_match\": np.mean(em_scores) * 100,\n",
    "        \"f1\": np.mean(f1_scores) * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e6dd5",
   "metadata": {},
   "source": [
    "### Set training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79ac350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncating train dataset: 100%|██████████| 9000/9000 [00:00<00:00, 132281.36 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 1669/1669 [00:00<00:00, 138266.48 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = tokenized_train_dataset.select(range(9000))\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"tat-llm\",\n",
    "    max_seq_length=1024,\n",
    "    # max_steps=100,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=2,\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    eval_strategy=\"no\",\n",
    "    # eval_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    # report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=sft_config,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[PrintLossCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79add608",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a725c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18000' max='18000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18000/18000 11:00:47, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.614900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.570700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.532200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.507700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.464300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.451700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.436700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.391500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.383200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.354000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.335800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.336600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.267200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.248900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.191100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.185300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.150900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.136900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.099100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.087800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.083100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 | Loss: 0.6149 | LR: 0.0002\n",
      "Step 400 | Loss: 0.5707 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 | Loss: 0.5322 | LR: 0.0002\n",
      "Step 800 | Loss: 0.5231 | LR: 0.0002\n",
      "Step 1000 | Loss: 0.5077 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1200 | Loss: 0.4991 | LR: 0.0002\n",
      "Step 1400 | Loss: 0.4973 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600 | Loss: 0.4772 | LR: 0.0002\n",
      "Step 1800 | Loss: 0.4643 | LR: 0.0002\n",
      "Step 2000 | Loss: 0.4517 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2200 | Loss: 0.4374 | LR: 0.0002\n",
      "Step 2400 | Loss: 0.4367 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2600 | Loss: 0.4224 | LR: 0.0002\n",
      "Step 2800 | Loss: 0.4126 | LR: 0.0002\n",
      "Step 3000 | Loss: 0.3915 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3200 | Loss: 0.3832 | LR: 0.0002\n",
      "Step 3400 | Loss: 0.3763 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3600 | Loss: 0.3540 | LR: 0.0002\n",
      "Step 3800 | Loss: 0.3505 | LR: 0.0002\n",
      "Step 4000 | Loss: 0.3358 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4200 | Loss: 0.3341 | LR: 0.0002\n",
      "Step 4400 | Loss: 0.3366 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4600 | Loss: 0.2891 | LR: 0.0002\n",
      "Step 4800 | Loss: 0.2711 | LR: 0.0002\n",
      "Step 5000 | Loss: 0.2786 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5200 | Loss: 0.2575 | LR: 0.0002\n",
      "Step 5400 | Loss: 0.2672 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5600 | Loss: 0.2473 | LR: 0.0002\n",
      "Step 5800 | Loss: 0.2489 | LR: 0.0002\n",
      "Step 6000 | Loss: 0.2338 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6200 | Loss: 0.2218 | LR: 0.0002\n",
      "Step 6400 | Loss: 0.2312 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6600 | Loss: 0.2217 | LR: 0.0002\n",
      "Step 6800 | Loss: 0.2129 | LR: 0.0002\n",
      "Step 7000 | Loss: 0.2099 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7200 | Loss: 0.2113 | LR: 0.0002\n",
      "Step 7400 | Loss: 0.2087 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7600 | Loss: 0.2056 | LR: 0.0002\n",
      "Step 7800 | Loss: 0.1938 | LR: 0.0002\n",
      "Step 8000 | Loss: 0.1999 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8200 | Loss: 0.1911 | LR: 0.0002\n",
      "Step 8400 | Loss: 0.1853 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8600 | Loss: 0.1861 | LR: 0.0002\n",
      "Step 8800 | Loss: 0.1869 | LR: 0.0002\n",
      "Step 9000 | Loss: 0.1766 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9200 | Loss: 0.1616 | LR: 0.0002\n",
      "Step 9400 | Loss: 0.1590 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9600 | Loss: 0.1548 | LR: 0.0002\n",
      "Step 9800 | Loss: 0.1509 | LR: 0.0002\n",
      "Step 10000 | Loss: 0.1538 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10200 | Loss: 0.1547 | LR: 0.0002\n",
      "Step 10400 | Loss: 0.1540 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10600 | Loss: 0.1556 | LR: 0.0002\n",
      "Step 10800 | Loss: 0.1482 | LR: 0.0002\n",
      "Step 11000 | Loss: 0.1506 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11200 | Loss: 0.1498 | LR: 0.0002\n",
      "Step 11400 | Loss: 0.1452 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11600 | Loss: 0.1407 | LR: 0.0002\n",
      "Step 11800 | Loss: 0.1344 | LR: 0.0002\n",
      "Step 12000 | Loss: 0.1366 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12200 | Loss: 0.1354 | LR: 0.0002\n",
      "Step 12400 | Loss: 0.1408 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12600 | Loss: 0.1369 | LR: 0.0002\n",
      "Step 12800 | Loss: 0.1355 | LR: 0.0002\n",
      "Step 13000 | Loss: 0.1350 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13200 | Loss: 0.1339 | LR: 0.0002\n",
      "Step 13400 | Loss: 0.1266 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13600 | Loss: 0.1155 | LR: 0.0002\n",
      "Step 13800 | Loss: 0.1129 | LR: 0.0002\n",
      "Step 14000 | Loss: 0.1111 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14200 | Loss: 0.1096 | LR: 0.0002\n",
      "Step 14400 | Loss: 0.1082 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14600 | Loss: 0.1005 | LR: 0.0002\n",
      "Step 14800 | Loss: 0.1081 | LR: 0.0002\n",
      "Step 15000 | Loss: 0.1000 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15200 | Loss: 0.1015 | LR: 0.0002\n",
      "Step 15400 | Loss: 0.1021 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15600 | Loss: 0.1039 | LR: 0.0002\n",
      "Step 15800 | Loss: 0.1018 | LR: 0.0002\n",
      "Step 16000 | Loss: 0.0991 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16200 | Loss: 0.0891 | LR: 0.0002\n",
      "Step 16400 | Loss: 0.0962 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16600 | Loss: 0.0906 | LR: 0.0002\n",
      "Step 16800 | Loss: 0.0924 | LR: 0.0002\n",
      "Step 17000 | Loss: 0.0907 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17200 | Loss: 0.0875 | LR: 0.0002\n",
      "Step 17400 | Loss: 0.0878 | LR: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17600 | Loss: 0.0830 | LR: 0.0002\n",
      "Step 17800 | Loss: 0.0874 | LR: 0.0002\n",
      "Step 18000 | Loss: 0.0831 | LR: 0.0002\n",
      "Step 18000 | Available metrics: train_runtime, train_samples_per_second, train_steps_per_second, total_flos, train_loss, epoch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18000, training_loss=0.22556510406070285, metrics={'train_runtime': 39649.9004, 'train_samples_per_second': 0.908, 'train_steps_per_second': 0.454, 'total_flos': 1.578796188696576e+18, 'train_loss': 0.22556510406070285})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39a402",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bc7e778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tat-llm-final-e4\\\\tokenizer_config.json',\n",
       " 'tat-llm-final-e4\\\\special_tokens_map.json',\n",
       " 'tat-llm-final-e4\\\\chat_template.jinja',\n",
       " 'tat-llm-final-e4\\\\tokenizer.model',\n",
       " 'tat-llm-final-e4\\\\added_tokens.json',\n",
       " 'tat-llm-final-e4\\\\tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"tat-llm-final-e4\")          # saves model + LoRA adapter\n",
    "tokenizer.save_pretrained(\"tat-llm-final-e4\")   # saves tokenizer config/vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92e61b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"model_name\": \"tat-llm-final-e4\",\n",
    "    \"base_model\": \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
    "    \"tokenizer\": \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
    "    \"adapter_type\": \"LoRA\",\n",
    "    \"adapter_config\": {\n",
    "        \"r\": peft_config.r,\n",
    "        \"alpha\": peft_config.lora_alpha,\n",
    "        \"dropout\": peft_config.lora_dropout,\n",
    "        \"bias\": peft_config.bias\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"dataset\": \"TAT-QA (train.json)\",\n",
    "        \"num_examples\": 9000,\n",
    "        \"num_epochs\": 4,\n",
    "        \"max_seq_length\": 1024,\n",
    "        \"batch_size_per_device\": sft_config.per_device_train_batch_size,\n",
    "        \"learning_rate\": sft_config.learning_rate,\n",
    "        \"lr_scheduler\": sft_config.lr_scheduler_type,\n",
    "        \"fp16\": sft_config.fp16,\n",
    "        \"bf16\": sft_config.bf16,\n",
    "        \"optimizer\": \"AdamW (via Trainer)\"\n",
    "    },\n",
    "    \"notes\": \"Instruction-tuned with simplified prompt format. No evaluation run due to memory constraints. Use .generate() for inference.\",\n",
    "    \"created_by\": \"Your Name or Team\",\n",
    "    \"date\": \"2025-07-08\"\n",
    "}\n",
    "\n",
    "with open(\"tat-llm-final-e4/metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99744cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "with open(\"tat-llm-final-e4/training_args.json\", \"w\") as f:\n",
    "    json.dump(asdict(sft_config), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0137fca8",
   "metadata": {},
   "source": [
    "## Evaluate the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972e806",
   "metadata": {},
   "source": [
    "### Load the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b21fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "c:\\conda\\envs\\torch-gpu\\lib\\site-packages\\peft\\peft_model.py:585: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    }
   ],
   "source": [
    "lora_model = PeftModel.from_pretrained(model, \"tat-llm-final-e4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8143e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tat-llm-final-e4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4203b3",
   "metadata": {},
   "source": [
    "### Evaluate with range 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cac685bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 1/50 [00:38<31:37, 38.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 2/50 [01:15<30:09, 37.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 3/50 [01:53<29:24, 37.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 4/50 [02:32<29:28, 38.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 5/50 [03:09<28:17, 37.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 6/50 [03:48<28:08, 38.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 7/50 [04:28<27:47, 38.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 8/50 [05:08<27:18, 39.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 9/50 [05:47<26:46, 39.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 10/50 [06:25<25:48, 38.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 11/50 [07:03<25:03, 38.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 12/50 [07:42<24:34, 38.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 13/50 [08:18<23:17, 37.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 14/50 [08:55<22:31, 37.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 15/50 [09:32<21:47, 37.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 16/50 [10:11<21:34, 38.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 17/50 [10:51<21:10, 38.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 18/50 [11:30<20:39, 38.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 19/50 [12:10<20:09, 39.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 20/50 [12:50<19:37, 39.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 21/50 [13:29<19:01, 39.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 22/50 [14:09<18:25, 39.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 23/50 [14:49<17:46, 39.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 24/50 [15:28<17:06, 39.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 25/50 [16:05<16:06, 38.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 26/50 [16:41<15:13, 38.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 27/50 [17:17<14:21, 37.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 28/50 [17:57<13:59, 38.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 29/50 [18:37<13:32, 38.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 30/50 [19:17<12:58, 38.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 31/50 [19:56<12:20, 38.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 32/50 [20:35<11:42, 39.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 33/50 [21:14<11:02, 38.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 34/50 [21:53<10:23, 38.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 35/50 [22:32<09:43, 38.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 36/50 [23:10<09:04, 38.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 37/50 [23:46<08:14, 38.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 38/50 [24:23<07:29, 37.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 39/50 [24:59<06:49, 37.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 40/50 [25:38<06:15, 37.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 41/50 [26:18<05:44, 38.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 42/50 [26:55<05:04, 38.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 43/50 [27:31<04:22, 37.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 44/50 [28:09<03:45, 37.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 45/50 [28:45<03:05, 37.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 46/50 [29:26<02:32, 38.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 47/50 [30:06<01:56, 38.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 48/50 [30:46<01:18, 39.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 49/50 [31:24<00:38, 38.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|██████████| 50/50 [32:02<00:00, 38.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EM: 0.00\n",
      "F1: 46.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "em_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "subset_dataset = tokenized_test_dataset.select(range(50))\n",
    "lora_model.eval()\n",
    "\n",
    "for i in tqdm(range(len(subset_dataset)), desc=\"Evaluating\"):\n",
    "    sample = subset_dataset[i]\n",
    "\n",
    "    input_ids = torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(sample[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = lora_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    pred_str = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Gold label: decode from true token IDs without -100\n",
    "    if \"labels\" in sample:\n",
    "        label = np.array(sample[\"labels\"])\n",
    "        label = label[label != -100]\n",
    "        label_str = tokenizer.decode(label, skip_special_tokens=True)\n",
    "    else:\n",
    "        label_str = sample[\"answer\"]    # fallback if using original dataset\n",
    "\n",
    "    em = compute_exact(pred_str, label_str)\n",
    "    f1 = compute_f1(pred_str, label_str)\n",
    "\n",
    "    em_scores.append(em)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"\\nEM: {100 * np.mean(em_scores):.2f}\")\n",
    "print(f\"F1: {100 * np.mean(f1_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7ea1c",
   "metadata": {},
   "source": [
    "### Evaluate with range 50 (random sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7e37c4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 1/50 [00:12<10:09, 12.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 2/50 [00:24<09:39, 12.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 3/50 [00:34<08:56, 11.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 4/50 [00:44<08:18, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 5/50 [00:55<08:01, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 6/50 [01:06<08:05, 11.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 7/50 [01:17<07:52, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 8/50 [01:24<06:49,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 9/50 [01:32<06:11,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 10/50 [01:41<06:03,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 11/50 [01:52<06:16,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 12/50 [02:00<05:52,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 13/50 [02:11<05:54,  9.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 14/50 [02:22<05:59,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 15/50 [02:32<05:54, 10.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 16/50 [02:43<05:51, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 17/50 [02:55<05:55, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 18/50 [03:06<05:44, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 19/50 [03:14<05:08,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 20/50 [03:25<05:07, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 21/50 [03:36<05:03, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 22/50 [03:46<04:55, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 23/50 [03:58<04:53, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 24/50 [04:06<04:24, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 25/50 [04:17<04:19, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 26/50 [04:28<04:12, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 27/50 [04:39<04:03, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 28/50 [04:50<03:54, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 29/50 [05:00<03:43, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 30/50 [05:11<03:33, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 31/50 [05:21<03:18, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 32/50 [05:30<02:59,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 33/50 [05:39<02:45,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 34/50 [05:50<02:40, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 35/50 [05:59<02:24,  9.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 36/50 [06:08<02:15,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 37/50 [06:20<02:12, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 38/50 [06:30<02:01, 10.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 39/50 [06:40<01:53, 10.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 40/50 [06:52<01:46, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 41/50 [07:03<01:38, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 42/50 [07:15<01:28, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 43/50 [07:26<01:17, 11.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 44/50 [07:34<01:01, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 45/50 [07:43<00:49,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 46/50 [07:54<00:40, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 47/50 [08:06<00:31, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 48/50 [08:17<00:21, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 49/50 [08:26<00:10, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|██████████| 50/50 [08:37<00:00, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EM: 0.00\n",
      "F1: 44.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "em_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "subset_indices = random.sample(range(len(tokenized_test_dataset)), 50)\n",
    "subset_dataset = tokenized_test_dataset.select(subset_indices)\n",
    "lora_model.eval()\n",
    "\n",
    "for i in tqdm(range(len(subset_dataset)), desc=\"Evaluating\"):\n",
    "    sample = subset_dataset[i]\n",
    "\n",
    "    input_ids = torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(sample[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = lora_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    pred_str = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Gold label: decode from true token IDs without -100\n",
    "    if \"labels\" in sample:\n",
    "        label = np.array(sample[\"labels\"])\n",
    "        label = label[label != -100]\n",
    "        label_str = tokenizer.decode(label, skip_special_tokens=True)\n",
    "    else:\n",
    "        label_str = sample[\"answer\"]    # fallback if using original dataset\n",
    "\n",
    "    em = compute_exact(pred_str, label_str)\n",
    "    f1 = compute_f1(pred_str, label_str)\n",
    "\n",
    "    em_scores.append(em)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"\\nEM: {100 * np.mean(em_scores):.2f}\")\n",
    "print(f\"F1: {100 * np.mean(f1_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c7a00",
   "metadata": {},
   "source": [
    "### Evaluate with range 100 (random sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4b0b0ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 1/100 [00:11<19:07, 11.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 2/100 [00:20<15:58,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 3/100 [00:29<15:33,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 4/100 [00:41<16:43, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 5/100 [00:52<16:50, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 6/100 [01:03<16:46, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 7/100 [01:12<16:07, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 8/100 [01:23<16:02, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 9/100 [01:35<16:24, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 10/100 [01:45<16:04, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 11/100 [01:56<15:58, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 12/100 [02:08<16:11, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 13/100 [02:19<16:15, 11.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 14/100 [02:30<15:57, 11.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 15/100 [02:39<14:51, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 16/100 [02:50<14:55, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 17/100 [02:59<14:05, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 18/100 [03:11<14:27, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 19/100 [03:22<14:22, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 20/100 [03:33<14:32, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 21/100 [03:44<14:20, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 22/100 [03:54<13:59, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 23/100 [04:03<12:57, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 24/100 [04:15<13:25, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 25/100 [04:24<12:56, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 26/100 [04:36<13:14, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 27/100 [04:47<13:08, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 28/100 [04:58<12:57, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 29/100 [05:08<12:24, 10.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 30/100 [05:19<12:38, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 31/100 [05:30<12:22, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 32/100 [05:37<11:02,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 33/100 [05:49<11:29, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 34/100 [05:59<11:14, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 35/100 [06:09<11:06, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 36/100 [06:18<10:36,  9.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 37/100 [06:30<10:55, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 38/100 [06:41<10:51, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 39/100 [06:52<11:04, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 40/100 [07:04<11:06, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 41/100 [07:12<09:58, 10.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 42/100 [07:22<09:47, 10.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 43/100 [07:33<09:47, 10.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 44/100 [07:42<09:27, 10.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 45/100 [07:53<09:32, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 46/100 [08:03<09:02, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 47/100 [08:14<09:05, 10.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 48/100 [08:23<08:37,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 49/100 [08:30<07:46,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 50/100 [08:39<07:33,  9.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 51/100 [08:51<08:03,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 52/100 [09:02<08:14, 10.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 53/100 [09:13<08:12, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 54/100 [09:25<08:18, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 55/100 [09:35<08:09, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 56/100 [09:47<08:12, 11.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 57/100 [09:58<07:58, 11.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 58/100 [10:09<07:46, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 59/100 [10:20<07:23, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 60/100 [10:31<07:23, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 61/100 [10:42<07:11, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 62/100 [10:51<06:35, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 63/100 [11:03<06:41, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 64/100 [11:15<06:40, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 65/100 [11:25<06:23, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 66/100 [11:36<06:11, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 67/100 [11:47<06:01, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 68/100 [11:58<05:48, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 69/100 [12:06<05:14, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 70/100 [12:16<04:59,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 71/100 [12:27<04:56, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 72/100 [12:37<04:48, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 73/100 [12:49<04:48, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 74/100 [13:01<04:45, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 75/100 [13:10<04:22, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 76/100 [13:18<03:54,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 77/100 [13:30<03:57, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 78/100 [13:37<03:29,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 79/100 [13:47<03:23,  9.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 80/100 [13:59<03:27, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 81/100 [14:11<03:24, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 82/100 [14:23<03:18, 11.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 83/100 [14:34<03:10, 11.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 84/100 [14:46<03:01, 11.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 85/100 [14:56<02:46, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 86/100 [15:07<02:34, 11.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 87/100 [15:15<02:09,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 88/100 [15:26<02:04, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 89/100 [15:37<01:55, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 90/100 [15:48<01:48, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 91/100 [16:00<01:39, 11.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 92/100 [16:11<01:27, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 93/100 [16:20<01:13, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 94/100 [16:31<01:04, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 95/100 [16:43<00:54, 10.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 96/100 [16:52<00:40, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 97/100 [17:02<00:30, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 98/100 [17:10<00:19,  9.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 99/100 [17:22<00:10, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|██████████| 100/100 [17:33<00:00, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EM: 0.00\n",
      "F1: 46.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "em_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "subset_indices = random.sample(range(len(tokenized_test_dataset)), 100)\n",
    "subset_dataset = tokenized_test_dataset.select(subset_indices)\n",
    "lora_model.eval()\n",
    "\n",
    "for i in tqdm(range(len(subset_dataset)), desc=\"Evaluating\"):\n",
    "    sample = subset_dataset[i]\n",
    "\n",
    "    input_ids = torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(sample[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = lora_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    pred_str = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Gold label: decode from true token IDs without -100\n",
    "    if \"labels\" in sample:\n",
    "        label = np.array(sample[\"labels\"])\n",
    "        label = label[label != -100]\n",
    "        label_str = tokenizer.decode(label, skip_special_tokens=True)\n",
    "    else:\n",
    "        label_str = sample[\"answer\"]    # fallback if using original dataset\n",
    "\n",
    "    em = compute_exact(pred_str, label_str)\n",
    "    f1 = compute_f1(pred_str, label_str)\n",
    "\n",
    "    em_scores.append(em)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"\\nEM: {100 * np.mean(em_scores):.2f}\")\n",
    "print(f\"F1: {100 * np.mean(f1_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d4875",
   "metadata": {},
   "source": [
    "### Evaluate with full test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fd7f3ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1669 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 1/1669 [00:10<4:50:17, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 2/1669 [00:19<4:34:05,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 3/1669 [00:29<4:30:35,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 4/1669 [00:41<4:53:06, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 5/1669 [00:50<4:34:05,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 6/1669 [01:02<4:54:04, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 7/1669 [01:13<5:05:27, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   0%|          | 8/1669 [01:25<5:13:54, 11.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 9/1669 [01:37<5:17:19, 11.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 10/1669 [01:47<5:03:32, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 11/1669 [01:57<4:58:39, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 12/1669 [02:09<5:07:48, 11.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 13/1669 [02:17<4:38:11, 10.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 14/1669 [02:26<4:31:50,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 15/1669 [02:36<4:26:35,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 16/1669 [02:47<4:43:35, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 17/1669 [02:59<4:55:48, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 18/1669 [03:11<5:03:45, 11.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 19/1669 [03:23<5:10:48, 11.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|          | 20/1669 [03:35<5:15:24, 11.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|▏         | 21/1669 [03:46<5:18:05, 11.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|▏         | 22/1669 [03:58<5:20:23, 11.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|▏         | 23/1669 [04:10<5:21:39, 11.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|▏         | 24/1669 [04:22<5:22:36, 11.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   1%|▏         | 25/1669 [04:31<5:00:11, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 26/1669 [04:40<4:44:01, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 27/1669 [04:48<4:26:26,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 28/1669 [05:00<4:43:31, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 29/1669 [05:12<4:55:03, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 30/1669 [05:23<4:58:55, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 31/1669 [05:34<4:58:28, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 32/1669 [05:45<4:59:30, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 33/1669 [05:56<5:00:08, 11.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 34/1669 [06:07<4:59:31, 10.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 35/1669 [06:18<4:57:54, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 36/1669 [06:29<4:55:43, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 37/1669 [06:37<4:34:25, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 38/1669 [06:46<4:20:19,  9.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 39/1669 [06:54<4:13:16,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 40/1669 [07:05<4:22:25,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   2%|▏         | 41/1669 [07:16<4:37:40, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 42/1669 [07:26<4:32:45, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 43/1669 [07:34<4:18:48,  9.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 44/1669 [07:44<4:21:28,  9.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 45/1669 [07:52<4:07:16,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 46/1669 [08:04<4:26:42,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 47/1669 [08:15<4:41:12, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 48/1669 [08:27<4:51:16, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 49/1669 [08:37<4:44:04, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 50/1669 [08:47<4:38:18, 10.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 51/1669 [08:54<4:16:47,  9.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 52/1669 [09:04<4:14:37,  9.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 53/1669 [09:15<4:32:23, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 54/1669 [09:26<4:32:48, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 55/1669 [09:37<4:44:50, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 56/1669 [09:49<4:51:40, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 57/1669 [09:57<4:28:22,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   3%|▎         | 58/1669 [10:08<4:41:32, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▎         | 59/1669 [10:18<4:37:22, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▎         | 60/1669 [10:30<4:47:14, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▎         | 61/1669 [10:39<4:37:51, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▎         | 62/1669 [10:51<4:46:37, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 63/1669 [10:59<4:21:40,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 64/1669 [11:07<4:10:33,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 65/1669 [11:18<4:27:58, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 66/1669 [11:28<4:20:32,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 67/1669 [11:37<4:18:39,  9.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 68/1669 [11:46<4:12:39,  9.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 69/1669 [11:55<4:04:11,  9.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 70/1669 [12:04<4:09:24,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 71/1669 [12:16<4:27:52, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 72/1669 [12:26<4:30:04, 10.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 73/1669 [12:37<4:34:29, 10.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 74/1669 [12:48<4:36:52, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   4%|▍         | 75/1669 [12:59<4:40:10, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 76/1669 [13:09<4:41:01, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 77/1669 [13:20<4:43:22, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 78/1669 [13:31<4:43:33, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 79/1669 [13:42<4:49:36, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 80/1669 [13:54<4:54:47, 11.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 81/1669 [14:06<4:58:48, 11.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 82/1669 [14:16<4:47:59, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▍         | 83/1669 [14:25<4:37:12, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 84/1669 [14:37<4:45:27, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 85/1669 [14:47<4:44:59, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 86/1669 [14:58<4:44:53, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 87/1669 [15:09<4:44:23, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 88/1669 [15:20<4:43:49, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 89/1669 [15:31<4:44:25, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 90/1669 [15:41<4:43:27, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   5%|▌         | 91/1669 [15:52<4:43:28, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 92/1669 [16:03<4:44:41, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 93/1669 [16:14<4:43:17, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 94/1669 [16:25<4:43:35, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 95/1669 [16:35<4:43:31, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 96/1669 [16:47<4:45:41, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 97/1669 [16:56<4:31:10, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 98/1669 [17:06<4:29:13, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 99/1669 [17:15<4:23:42, 10.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 100/1669 [17:24<4:13:32,  9.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 101/1669 [17:35<4:23:03, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 102/1669 [17:44<4:14:31,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 103/1669 [17:52<3:57:11,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▌         | 104/1669 [18:00<3:51:35,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▋         | 105/1669 [18:08<3:47:36,  8.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▋         | 106/1669 [18:20<4:11:35,  9.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▋         | 107/1669 [18:32<4:27:15, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   6%|▋         | 108/1669 [18:43<4:36:19, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 109/1669 [18:52<4:20:43, 10.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 110/1669 [19:01<4:11:06,  9.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 111/1669 [19:09<4:00:13,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 112/1669 [19:21<4:18:57,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 113/1669 [19:32<4:31:27, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 114/1669 [19:43<4:34:27, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 115/1669 [19:50<4:06:17,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 116/1669 [19:57<3:46:27,  8.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 117/1669 [20:04<3:32:30,  8.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 118/1669 [20:11<3:22:46,  7.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 119/1669 [20:18<3:16:51,  7.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 120/1669 [20:25<3:11:35,  7.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 121/1669 [20:36<3:37:13,  8.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 122/1669 [20:47<3:55:12,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 123/1669 [20:58<4:07:50,  9.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 124/1669 [21:08<4:17:15,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   7%|▋         | 125/1669 [21:19<4:23:45, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 126/1669 [21:30<4:28:29, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 127/1669 [21:39<4:14:04,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 128/1669 [21:50<4:27:04, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 129/1669 [22:02<4:36:17, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 130/1669 [22:12<4:30:38, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 131/1669 [22:21<4:18:21, 10.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 132/1669 [22:30<4:09:51,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 133/1669 [22:40<4:15:08,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 134/1669 [22:51<4:20:00, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 135/1669 [23:02<4:22:50, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 136/1669 [23:12<4:24:40, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 137/1669 [23:23<4:26:21, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 138/1669 [23:33<4:26:59, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 139/1669 [23:42<4:11:17,  9.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 140/1669 [23:52<4:14:46, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   8%|▊         | 141/1669 [24:03<4:22:27, 10.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▊         | 142/1669 [24:13<4:18:39, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▊         | 143/1669 [24:22<4:13:23,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▊         | 144/1669 [24:33<4:21:22, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▊         | 145/1669 [24:45<4:30:53, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▊         | 146/1669 [24:54<4:18:53, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 147/1669 [25:06<4:28:45, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 148/1669 [25:17<4:35:30, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 149/1669 [25:29<4:41:28, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 150/1669 [25:40<4:44:31, 11.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 151/1669 [25:51<4:40:58, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 152/1669 [26:02<4:38:45, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 153/1669 [26:13<4:37:12, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 154/1669 [26:24<4:35:33, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 155/1669 [26:35<4:36:20, 10.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 156/1669 [26:45<4:34:16, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 157/1669 [26:56<4:34:33, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:   9%|▉         | 158/1669 [27:07<4:34:54, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 159/1669 [27:18<4:34:51, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 160/1669 [27:29<4:34:10, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 161/1669 [27:40<4:32:11, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 162/1669 [27:51<4:32:17, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 163/1669 [28:02<4:36:43, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 164/1669 [28:10<4:14:37, 10.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 165/1669 [28:17<3:52:29,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|▉         | 166/1669 [28:27<3:56:13,  9.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 167/1669 [28:36<3:48:40,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 168/1669 [28:47<4:02:27,  9.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 169/1669 [28:57<4:11:20, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 170/1669 [29:08<4:16:30, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 171/1669 [29:19<4:19:46, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 172/1669 [29:30<4:22:33, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 173/1669 [29:41<4:24:52, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 174/1669 [29:51<4:25:42, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  10%|█         | 175/1669 [30:02<4:27:34, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 176/1669 [30:13<4:27:05, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 177/1669 [30:24<4:26:46, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 178/1669 [30:35<4:27:39, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 179/1669 [30:45<4:27:13, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 180/1669 [30:56<4:26:32, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 181/1669 [31:05<4:10:43, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 182/1669 [31:13<3:58:55,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 183/1669 [31:22<3:50:57,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 184/1669 [31:30<3:45:21,  9.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 185/1669 [31:39<3:40:46,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 186/1669 [31:47<3:37:24,  8.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█         | 187/1669 [31:58<3:50:38,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█▏        | 188/1669 [32:09<4:01:12,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█▏        | 189/1669 [32:19<4:07:35, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█▏        | 190/1669 [32:30<4:11:34, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  11%|█▏        | 191/1669 [32:41<4:16:01, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 192/1669 [32:52<4:17:52, 10.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 193/1669 [33:01<4:06:34, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 194/1669 [33:09<3:55:49,  9.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 195/1669 [33:19<3:57:07,  9.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 196/1669 [33:30<4:11:10, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 197/1669 [33:41<4:11:38, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 198/1669 [33:51<4:09:32, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 199/1669 [33:58<3:46:40,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 200/1669 [34:09<4:02:35,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 201/1669 [34:21<4:15:37, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 202/1669 [34:31<4:15:03, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 203/1669 [34:43<4:23:29, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 204/1669 [34:53<4:17:50, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 205/1669 [35:01<4:01:19,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 206/1669 [35:10<3:49:24,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 207/1669 [35:21<4:04:42, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  12%|█▏        | 208/1669 [35:31<4:05:37, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 209/1669 [35:40<3:52:22,  9.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 210/1669 [35:50<3:57:41,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 211/1669 [35:59<3:52:20,  9.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 212/1669 [36:09<3:51:41,  9.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 213/1669 [36:17<3:46:33,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 214/1669 [36:29<4:03:04, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 215/1669 [36:41<4:14:35, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 216/1669 [36:52<4:23:28, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 217/1669 [37:02<4:10:40, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 218/1669 [37:13<4:19:50, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 219/1669 [37:22<4:08:52, 10.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 220/1669 [37:34<4:17:28, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 221/1669 [37:46<4:24:04, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 222/1669 [37:55<4:12:10, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 223/1669 [38:06<4:13:47, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 224/1669 [38:16<4:15:53, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  13%|█▎        | 225/1669 [38:27<4:17:19, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▎        | 226/1669 [38:38<4:18:04, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▎        | 227/1669 [38:49<4:18:52, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▎        | 228/1669 [39:00<4:19:39, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▎        | 229/1669 [39:08<4:02:08, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 230/1669 [39:16<3:47:02,  9.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 231/1669 [39:26<3:47:50,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 232/1669 [39:36<3:55:37,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 233/1669 [39:47<3:57:21,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 234/1669 [39:56<3:52:25,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 235/1669 [40:07<3:59:59, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 236/1669 [40:18<4:05:57, 10.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 237/1669 [40:28<4:09:35, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 238/1669 [40:39<4:12:00, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 239/1669 [40:50<4:13:21, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 240/1669 [41:01<4:14:56, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 241/1669 [41:05<3:31:24,  8.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  14%|█▍        | 242/1669 [41:10<3:01:36,  7.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 243/1669 [41:15<2:39:56,  6.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 244/1669 [41:19<2:24:54,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 245/1669 [41:24<2:14:40,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 246/1669 [41:29<2:08:13,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 247/1669 [41:40<2:45:33,  6.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 248/1669 [41:51<3:17:36,  8.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 249/1669 [41:59<3:15:34,  8.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▍        | 250/1669 [42:10<3:31:13,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 251/1669 [42:21<3:45:39,  9.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 252/1669 [42:31<3:48:22,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 253/1669 [42:39<3:42:05,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 254/1669 [42:50<3:50:23,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 255/1669 [42:59<3:46:58,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 256/1669 [43:09<3:48:43,  9.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 257/1669 [43:21<4:01:49, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  15%|█▌        | 258/1669 [43:31<4:02:48, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 259/1669 [43:43<4:11:01, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 260/1669 [43:54<4:16:01, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 261/1669 [44:06<4:20:47, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 262/1669 [44:17<4:23:30, 11.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 263/1669 [44:29<4:24:45, 11.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 264/1669 [44:39<4:15:54, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 265/1669 [44:50<4:20:10, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 266/1669 [44:59<4:02:09, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 267/1669 [45:05<3:31:44,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 268/1669 [45:15<3:36:09,  9.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 269/1669 [45:26<3:46:39,  9.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 270/1669 [45:36<3:53:33, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▌        | 271/1669 [45:48<4:03:40, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▋        | 272/1669 [45:59<4:11:54, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▋        | 273/1669 [46:11<4:17:20, 11.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▋        | 274/1669 [46:23<4:20:51, 11.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  16%|█▋        | 275/1669 [46:34<4:20:35, 11.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 276/1669 [46:44<4:16:10, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 277/1669 [46:56<4:19:02, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 278/1669 [47:04<4:00:14, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 279/1669 [47:16<4:05:25, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 280/1669 [47:26<4:03:24, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 281/1669 [47:33<3:39:43,  9.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 282/1669 [47:45<3:54:39, 10.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 283/1669 [47:55<3:53:29, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 284/1669 [48:06<4:03:43, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 285/1669 [48:18<4:10:39, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 286/1669 [48:28<4:07:54, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 287/1669 [48:38<3:59:11, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 288/1669 [48:49<4:07:20, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 289/1669 [49:00<4:07:25, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 290/1669 [49:11<4:07:08, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 291/1669 [49:22<4:07:05, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  17%|█▋        | 292/1669 [49:33<4:06:55, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 293/1669 [49:43<4:07:01, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 294/1669 [49:54<4:06:24, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 295/1669 [50:05<4:10:17, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 296/1669 [50:17<4:14:59, 11.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 297/1669 [50:29<4:18:55, 11.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 298/1669 [50:38<4:05:57, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 299/1669 [50:48<4:00:46, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 300/1669 [50:59<4:04:38, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 301/1669 [51:11<4:09:02, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 302/1669 [51:22<4:13:55, 11.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 303/1669 [51:34<4:17:34, 11.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 304/1669 [51:45<4:13:44, 11.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 305/1669 [51:56<4:16:11, 11.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 306/1669 [52:06<4:05:00, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 307/1669 [52:16<3:59:23, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  18%|█▊        | 308/1669 [52:24<3:43:02,  9.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▊        | 309/1669 [52:36<3:54:49, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▊        | 310/1669 [52:46<3:56:22, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▊        | 311/1669 [52:57<3:58:54, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▊        | 312/1669 [53:09<4:05:40, 10.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 313/1669 [53:21<4:11:01, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 314/1669 [53:32<4:13:50, 11.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 315/1669 [53:44<4:17:41, 11.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 316/1669 [53:55<4:15:24, 11.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 317/1669 [54:03<3:53:44, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 318/1669 [54:13<3:52:37, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 319/1669 [54:24<3:55:36, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 320/1669 [54:35<3:57:44, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 321/1669 [54:46<3:59:41, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 322/1669 [54:57<3:59:37, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 323/1669 [55:07<3:59:37, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 324/1669 [55:18<4:00:18, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  19%|█▉        | 325/1669 [55:30<4:05:58, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 326/1669 [55:41<4:09:23, 11.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 327/1669 [55:53<4:11:37, 11.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 328/1669 [56:02<3:56:17, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 329/1669 [56:11<3:45:03, 10.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 330/1669 [56:20<3:42:30,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 331/1669 [56:28<3:29:54,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 332/1669 [56:40<3:42:01,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|█▉        | 333/1669 [56:51<3:52:39, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 334/1669 [57:03<3:59:58, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 335/1669 [57:11<3:41:59,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 336/1669 [57:22<3:47:08, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 337/1669 [57:30<3:33:51,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 338/1669 [57:40<3:33:40,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 339/1669 [57:51<3:45:54, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 340/1669 [58:03<3:55:22, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 341/1669 [58:14<3:56:41, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  20%|██        | 342/1669 [58:25<3:59:14, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 343/1669 [58:36<4:04:42, 11.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 344/1669 [58:45<3:46:08, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 345/1669 [58:56<3:54:55, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 346/1669 [59:07<3:53:14, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 347/1669 [59:18<3:54:33, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 348/1669 [59:29<4:01:30, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 349/1669 [59:34<3:16:49,  8.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 350/1669 [59:41<3:06:26,  8.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 351/1669 [59:50<3:11:25,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 352/1669 [1:00:01<3:25:50,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 353/1669 [1:00:13<3:40:33, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██        | 354/1669 [1:00:23<3:39:27, 10.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██▏       | 355/1669 [1:00:33<3:44:27, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██▏       | 356/1669 [1:00:44<3:47:08, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██▏       | 357/1669 [1:00:55<3:49:02, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  21%|██▏       | 358/1669 [1:01:06<3:51:27, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 359/1669 [1:01:16<3:52:44, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 360/1669 [1:01:27<3:54:13, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 361/1669 [1:01:35<3:35:20,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 362/1669 [1:01:44<3:28:14,  9.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 363/1669 [1:01:54<3:30:18,  9.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 364/1669 [1:02:05<3:40:55, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 365/1669 [1:02:15<3:35:34,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 366/1669 [1:02:26<3:42:46, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 367/1669 [1:02:34<3:28:26,  9.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 368/1669 [1:02:42<3:16:56,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 369/1669 [1:02:49<3:06:16,  8.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 370/1669 [1:02:58<3:09:27,  8.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 371/1669 [1:03:10<3:27:36,  9.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 372/1669 [1:03:20<3:32:05,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 373/1669 [1:03:23<2:49:58,  7.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 374/1669 [1:03:27<2:20:53,  6.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  22%|██▏       | 375/1669 [1:03:30<2:01:39,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 376/1669 [1:03:34<1:47:27,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 377/1669 [1:03:37<1:36:58,  4.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 378/1669 [1:03:41<1:29:53,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 379/1669 [1:03:51<2:08:22,  5.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 380/1669 [1:04:02<2:44:34,  7.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 381/1669 [1:04:14<3:09:16,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 382/1669 [1:04:22<3:06:01,  8.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 383/1669 [1:04:31<3:06:43,  8.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 384/1669 [1:04:43<3:25:09,  9.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 385/1669 [1:04:54<3:37:22, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 386/1669 [1:05:03<3:28:01,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 387/1669 [1:05:12<3:20:59,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 388/1669 [1:05:23<3:30:33,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 389/1669 [1:05:34<3:38:48, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 390/1669 [1:05:43<3:35:16, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 391/1669 [1:05:54<3:39:05, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  23%|██▎       | 392/1669 [1:06:05<3:42:39, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▎       | 393/1669 [1:06:16<3:44:34, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▎       | 394/1669 [1:06:27<3:45:13, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▎       | 395/1669 [1:06:37<3:45:49, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▎       | 396/1669 [1:06:48<3:46:20, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 397/1669 [1:07:00<3:51:49, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 398/1669 [1:07:11<3:55:13, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 399/1669 [1:07:20<3:40:12, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 400/1669 [1:07:29<3:33:27, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 401/1669 [1:07:39<3:33:49, 10.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 402/1669 [1:07:49<3:30:10,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 403/1669 [1:08:00<3:39:32, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 404/1669 [1:08:10<3:34:24, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 405/1669 [1:08:19<3:28:44,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 406/1669 [1:08:26<3:09:13,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 407/1669 [1:08:38<3:25:30,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  24%|██▍       | 408/1669 [1:08:49<3:37:28, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 409/1669 [1:09:00<3:39:01, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 410/1669 [1:09:08<3:24:52,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 411/1669 [1:09:16<3:14:52,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 412/1669 [1:09:27<3:25:12,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 413/1669 [1:09:39<3:34:00, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 414/1669 [1:09:48<3:30:39, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 415/1669 [1:09:59<3:35:42, 10.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 416/1669 [1:10:10<3:39:03, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▍       | 417/1669 [1:10:21<3:42:43, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 418/1669 [1:10:32<3:42:36, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 419/1669 [1:10:43<3:42:21, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 420/1669 [1:10:53<3:43:09, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 421/1669 [1:11:04<3:42:59, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 422/1669 [1:11:15<3:42:33, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 423/1669 [1:11:26<3:42:54, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 424/1669 [1:11:36<3:42:38, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  25%|██▌       | 425/1669 [1:11:47<3:42:16, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 426/1669 [1:11:58<3:41:54, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 427/1669 [1:12:07<3:31:05, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 428/1669 [1:12:16<3:26:06,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 429/1669 [1:12:25<3:21:15,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 430/1669 [1:12:37<3:30:23, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 431/1669 [1:12:47<3:30:38, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 432/1669 [1:12:57<3:33:11, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 433/1669 [1:13:08<3:35:23, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 434/1669 [1:13:19<3:37:39, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 435/1669 [1:13:30<3:38:47, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 436/1669 [1:13:41<3:38:52, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 437/1669 [1:13:51<3:38:51, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▌       | 438/1669 [1:14:02<3:39:05, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▋       | 439/1669 [1:14:13<3:40:32, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▋       | 440/1669 [1:14:24<3:45:33, 11.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▋       | 441/1669 [1:14:34<3:37:21, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  26%|██▋       | 442/1669 [1:14:46<3:43:15, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 443/1669 [1:14:57<3:47:40, 11.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 444/1669 [1:15:09<3:50:56, 11.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 445/1669 [1:15:21<3:53:49, 11.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 446/1669 [1:15:32<3:50:42, 11.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 447/1669 [1:15:44<3:52:46, 11.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 448/1669 [1:15:55<3:53:17, 11.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 449/1669 [1:16:07<3:54:22, 11.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 450/1669 [1:16:18<3:48:39, 11.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 451/1669 [1:16:28<3:42:32, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 452/1669 [1:16:38<3:39:31, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 453/1669 [1:16:49<3:37:57, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 454/1669 [1:16:59<3:36:24, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 455/1669 [1:17:10<3:34:04, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 456/1669 [1:17:20<3:34:02, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 457/1669 [1:17:31<3:33:55, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  27%|██▋       | 458/1669 [1:17:41<3:29:02, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 459/1669 [1:17:51<3:26:13, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 460/1669 [1:18:01<3:23:46, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 461/1669 [1:18:10<3:22:20, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 462/1669 [1:18:20<3:21:37, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 463/1669 [1:18:30<3:19:37,  9.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 464/1669 [1:18:42<3:29:04, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 465/1669 [1:18:52<3:28:38, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 466/1669 [1:19:01<3:18:26,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 467/1669 [1:19:12<3:27:45, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 468/1669 [1:19:22<3:24:14, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 469/1669 [1:19:33<3:27:17, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 470/1669 [1:19:40<3:09:47,  9.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 471/1669 [1:19:49<3:06:20,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 472/1669 [1:20:01<3:19:52, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 473/1669 [1:20:10<3:15:53,  9.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 474/1669 [1:20:20<3:15:48,  9.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  28%|██▊       | 475/1669 [1:20:30<3:18:01,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▊       | 476/1669 [1:20:41<3:22:57, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▊       | 477/1669 [1:20:52<3:26:23, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▊       | 478/1669 [1:21:03<3:28:14, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▊       | 479/1669 [1:21:13<3:29:55, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 480/1669 [1:21:24<3:31:58, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 481/1669 [1:21:35<3:32:26, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 482/1669 [1:21:47<3:36:04, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 483/1669 [1:21:54<3:14:59,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 484/1669 [1:22:03<3:12:44,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 485/1669 [1:22:13<3:08:50,  9.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 486/1669 [1:22:23<3:13:24,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 487/1669 [1:22:34<3:19:01, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 488/1669 [1:22:45<3:24:05, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 489/1669 [1:22:55<3:23:08, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 490/1669 [1:23:05<3:23:23, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 491/1669 [1:23:16<3:23:50, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  29%|██▉       | 492/1669 [1:23:27<3:30:58, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 493/1669 [1:23:39<3:34:57, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 494/1669 [1:23:50<3:34:37, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 495/1669 [1:23:59<3:23:49, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 496/1669 [1:24:11<3:30:16, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 497/1669 [1:24:21<3:26:10, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 498/1669 [1:24:32<3:32:32, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 499/1669 [1:24:40<3:15:26, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|██▉       | 500/1669 [1:24:51<3:19:34, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 501/1669 [1:25:02<3:23:13, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 502/1669 [1:25:13<3:25:20, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 503/1669 [1:25:24<3:26:05, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 504/1669 [1:25:34<3:26:51, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 505/1669 [1:25:45<3:27:23, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 506/1669 [1:25:56<3:28:18, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 507/1669 [1:26:07<3:27:36, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 508/1669 [1:26:17<3:27:35, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  30%|███       | 509/1669 [1:26:28<3:26:48, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 510/1669 [1:26:39<3:28:05, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 511/1669 [1:26:50<3:27:28, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 512/1669 [1:27:01<3:32:05, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 513/1669 [1:27:13<3:35:12, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 514/1669 [1:27:20<3:13:52, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 515/1669 [1:27:31<3:15:38, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 516/1669 [1:27:39<3:05:11,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 517/1669 [1:27:48<3:00:18,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 518/1669 [1:27:59<3:12:14, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 519/1669 [1:28:11<3:20:54, 10.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 520/1669 [1:28:22<3:26:25, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███       | 521/1669 [1:28:34<3:29:36, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███▏      | 522/1669 [1:28:45<3:32:10, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███▏      | 523/1669 [1:28:53<3:15:05, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███▏      | 524/1669 [1:29:03<3:12:56, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  31%|███▏      | 525/1669 [1:29:15<3:21:00, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 526/1669 [1:29:26<3:26:48, 10.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 527/1669 [1:29:38<3:30:26, 11.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 528/1669 [1:29:49<3:31:11, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 529/1669 [1:30:01<3:33:05, 11.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 530/1669 [1:30:12<3:34:40, 11.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 531/1669 [1:30:24<3:35:36, 11.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 532/1669 [1:30:35<3:33:49, 11.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 533/1669 [1:30:45<3:27:50, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 534/1669 [1:30:56<3:30:51, 11.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 535/1669 [1:31:08<3:33:23, 11.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 536/1669 [1:31:17<3:21:36, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 537/1669 [1:31:26<3:12:33, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 538/1669 [1:31:36<3:06:15,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 539/1669 [1:31:45<3:01:49,  9.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 540/1669 [1:31:54<2:59:56,  9.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 541/1669 [1:32:03<2:57:19,  9.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  32%|███▏      | 542/1669 [1:32:14<3:04:49,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 543/1669 [1:32:25<3:10:36, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 544/1669 [1:32:36<3:14:51, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 545/1669 [1:32:47<3:17:01, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 546/1669 [1:32:57<3:18:32, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 547/1669 [1:33:08<3:19:22, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 548/1669 [1:33:20<3:23:32, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 549/1669 [1:33:30<3:22:56, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 550/1669 [1:33:42<3:26:56, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 551/1669 [1:33:52<3:20:52, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 552/1669 [1:34:04<3:24:45, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 553/1669 [1:34:15<3:28:12, 11.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 554/1669 [1:34:27<3:30:40, 11.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 555/1669 [1:34:35<3:09:25, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 556/1669 [1:34:45<3:13:02, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 557/1669 [1:34:54<3:03:33,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 558/1669 [1:35:03<2:55:33,  9.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  33%|███▎      | 559/1669 [1:35:13<2:59:10,  9.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▎      | 560/1669 [1:35:24<3:05:48, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▎      | 561/1669 [1:35:35<3:09:52, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▎      | 562/1669 [1:35:45<3:12:34, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▎      | 563/1669 [1:35:56<3:15:08, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 564/1669 [1:36:07<3:15:50, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 565/1669 [1:36:18<3:16:28, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 566/1669 [1:36:28<3:12:04, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 567/1669 [1:36:37<3:05:41, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 568/1669 [1:36:47<3:02:47,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 569/1669 [1:36:56<2:56:49,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 570/1669 [1:37:06<3:00:13,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 571/1669 [1:37:17<3:09:53, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 572/1669 [1:37:26<3:00:07,  9.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 573/1669 [1:37:34<2:49:34,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 574/1669 [1:37:43<2:45:09,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  34%|███▍      | 575/1669 [1:37:52<2:48:10,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 576/1669 [1:38:03<2:57:59,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 577/1669 [1:38:14<3:05:07, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 578/1669 [1:38:26<3:12:50, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 579/1669 [1:38:35<3:04:50, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 580/1669 [1:38:44<2:55:01,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 581/1669 [1:38:53<2:53:09,  9.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 582/1669 [1:39:04<3:02:01, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 583/1669 [1:39:14<3:01:48, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▍      | 584/1669 [1:39:26<3:10:39, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 585/1669 [1:39:34<2:55:28,  9.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 586/1669 [1:39:42<2:49:00,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 587/1669 [1:39:54<3:01:31, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 588/1669 [1:40:05<3:08:06, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 589/1669 [1:40:15<3:07:14, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 590/1669 [1:40:27<3:13:56, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 591/1669 [1:40:36<3:04:00, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  35%|███▌      | 592/1669 [1:40:45<2:58:34,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 593/1669 [1:40:55<2:54:28,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 594/1669 [1:41:04<2:53:04,  9.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 595/1669 [1:41:14<2:54:25,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 596/1669 [1:41:25<2:58:51, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 597/1669 [1:41:32<2:46:49,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 598/1669 [1:41:44<2:59:48, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 599/1669 [1:41:55<3:02:04, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 600/1669 [1:42:06<3:07:03, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 601/1669 [1:42:18<3:13:10, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 602/1669 [1:42:27<3:03:28, 10.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 603/1669 [1:42:36<2:55:59,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 604/1669 [1:42:43<2:44:15,  9.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▌      | 605/1669 [1:42:52<2:39:12,  8.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▋      | 606/1669 [1:43:01<2:43:05,  9.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▋      | 607/1669 [1:43:12<2:52:20,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▋      | 608/1669 [1:43:24<3:02:42, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  36%|███▋      | 609/1669 [1:43:36<3:08:19, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 610/1669 [1:43:45<2:59:38, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 611/1669 [1:43:56<3:06:35, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 612/1669 [1:44:07<3:06:17, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 613/1669 [1:44:18<3:11:26, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 614/1669 [1:44:27<2:58:53, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 615/1669 [1:44:35<2:45:48,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 616/1669 [1:44:42<2:37:14,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 617/1669 [1:44:51<2:33:22,  8.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 618/1669 [1:45:00<2:35:57,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 619/1669 [1:45:11<2:49:25,  9.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 620/1669 [1:45:20<2:42:19,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 621/1669 [1:45:28<2:37:56,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 622/1669 [1:45:38<2:41:47,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 623/1669 [1:45:46<2:35:10,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 624/1669 [1:45:57<2:44:34,  9.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  37%|███▋      | 625/1669 [1:46:06<2:41:29,  9.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 626/1669 [1:46:16<2:48:56,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 627/1669 [1:46:27<2:54:27, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 628/1669 [1:46:38<2:57:39, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 629/1669 [1:46:49<3:00:16, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 630/1669 [1:46:59<3:02:03, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 631/1669 [1:47:10<3:02:53, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 632/1669 [1:47:20<2:59:37, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 633/1669 [1:47:27<2:42:03,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 634/1669 [1:47:35<2:35:03,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 635/1669 [1:47:46<2:44:21,  9.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 636/1669 [1:47:54<2:37:29,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 637/1669 [1:48:06<2:49:40,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 638/1669 [1:48:15<2:45:30,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 639/1669 [1:48:24<2:41:41,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 640/1669 [1:48:34<2:44:24,  9.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 641/1669 [1:48:45<2:51:19, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  38%|███▊      | 642/1669 [1:48:55<2:51:15, 10.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▊      | 643/1669 [1:49:05<2:50:33,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▊      | 644/1669 [1:49:13<2:39:41,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▊      | 645/1669 [1:49:21<2:32:26,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▊      | 646/1669 [1:49:28<2:26:00,  8.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 647/1669 [1:49:37<2:24:44,  8.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 648/1669 [1:49:48<2:40:09,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 649/1669 [1:50:00<2:50:48, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 650/1669 [1:50:11<2:57:34, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 651/1669 [1:50:23<3:03:12, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 652/1669 [1:50:34<3:06:54, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 653/1669 [1:50:43<2:55:27, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 654/1669 [1:50:54<2:56:34, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 655/1669 [1:51:05<3:01:41, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 656/1669 [1:51:15<2:56:01, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 657/1669 [1:51:25<2:52:28, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 658/1669 [1:51:36<2:57:53, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  39%|███▉      | 659/1669 [1:51:46<2:56:34, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 660/1669 [1:51:56<2:54:32, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 661/1669 [1:52:07<2:54:26, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 662/1669 [1:52:16<2:46:54,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 663/1669 [1:52:27<2:54:51, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 664/1669 [1:52:36<2:45:04,  9.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 665/1669 [1:52:46<2:47:17, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 666/1669 [1:52:57<2:49:13, 10.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|███▉      | 667/1669 [1:53:07<2:52:54, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 668/1669 [1:53:17<2:46:46, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 669/1669 [1:53:25<2:38:38,  9.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 670/1669 [1:53:33<2:32:58,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 671/1669 [1:53:44<2:39:07,  9.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 672/1669 [1:53:52<2:31:14,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 673/1669 [1:54:02<2:35:45,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 674/1669 [1:54:09<2:25:21,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  40%|████      | 675/1669 [1:54:21<2:40:14,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 676/1669 [1:54:32<2:49:02, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 677/1669 [1:54:41<2:42:13,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 678/1669 [1:54:51<2:40:29,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 679/1669 [1:55:02<2:46:11, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 680/1669 [1:55:13<2:49:52, 10.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 681/1669 [1:55:23<2:52:09, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 682/1669 [1:55:34<2:53:55, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 683/1669 [1:55:45<2:54:53, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 684/1669 [1:55:56<2:54:43, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 685/1669 [1:56:06<2:55:04, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 686/1669 [1:56:18<2:59:58, 10.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 687/1669 [1:56:26<2:46:43, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████      | 688/1669 [1:56:34<2:33:06,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████▏     | 689/1669 [1:56:43<2:33:43,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████▏     | 690/1669 [1:56:53<2:32:08,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████▏     | 691/1669 [1:57:04<2:43:19, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  41%|████▏     | 692/1669 [1:57:14<2:43:51, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 693/1669 [1:57:23<2:34:17,  9.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 694/1669 [1:57:31<2:27:54,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 695/1669 [1:57:40<2:27:03,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 696/1669 [1:57:49<2:27:14,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 697/1669 [1:57:59<2:31:27,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 698/1669 [1:58:10<2:42:40, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 699/1669 [1:58:18<2:30:25,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 700/1669 [1:58:26<2:21:54,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 701/1669 [1:58:35<2:23:24,  8.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 702/1669 [1:58:45<2:31:58,  9.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 703/1669 [1:58:55<2:34:07,  9.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 704/1669 [1:59:07<2:43:33, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 705/1669 [1:59:18<2:49:38, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 706/1669 [1:59:30<2:55:00, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 707/1669 [1:59:42<2:57:52, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 708/1669 [1:59:53<3:00:05, 11.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  42%|████▏     | 709/1669 [2:00:05<3:01:41, 11.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 710/1669 [2:00:16<3:02:53, 11.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 711/1669 [2:00:25<2:49:50, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 712/1669 [2:00:37<2:54:22, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 713/1669 [2:00:48<2:56:56, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 714/1669 [2:00:57<2:47:09, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 715/1669 [2:01:09<2:51:58, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 716/1669 [2:01:21<2:55:21, 11.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 717/1669 [2:01:29<2:42:24, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 718/1669 [2:01:40<2:48:13, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 719/1669 [2:01:52<2:52:32, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 720/1669 [2:02:03<2:54:46, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 721/1669 [2:02:13<2:48:56, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 722/1669 [2:02:24<2:48:29, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 723/1669 [2:02:35<2:48:10, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 724/1669 [2:02:45<2:48:21, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 725/1669 [2:02:56<2:48:17, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  43%|████▎     | 726/1669 [2:03:07<2:48:41, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▎     | 727/1669 [2:03:18<2:49:09, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▎     | 728/1669 [2:03:29<2:53:01, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▎     | 729/1669 [2:03:39<2:47:27, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▎     | 730/1669 [2:03:47<2:34:27,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 731/1669 [2:03:59<2:42:33, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 732/1669 [2:04:10<2:47:00, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 733/1669 [2:04:20<2:43:00, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 734/1669 [2:04:30<2:42:37, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 735/1669 [2:04:39<2:33:28,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 736/1669 [2:04:48<2:28:15,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 737/1669 [2:04:59<2:37:01, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 738/1669 [2:05:09<2:36:00, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 739/1669 [2:05:21<2:42:29, 10.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 740/1669 [2:05:31<2:43:32, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 741/1669 [2:05:42<2:44:15, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  44%|████▍     | 742/1669 [2:05:53<2:44:06, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 743/1669 [2:06:03<2:43:51, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 744/1669 [2:06:14<2:44:28, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 745/1669 [2:06:25<2:44:40, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 746/1669 [2:06:36<2:48:22, 10.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 747/1669 [2:06:48<2:51:07, 11.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 748/1669 [2:06:59<2:52:33, 11.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 749/1669 [2:07:10<2:48:26, 10.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 750/1669 [2:07:21<2:50:43, 11.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▍     | 751/1669 [2:07:33<2:52:12, 11.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 752/1669 [2:07:43<2:48:37, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 753/1669 [2:07:54<2:44:36, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 754/1669 [2:08:04<2:41:51, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 755/1669 [2:08:14<2:40:00, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 756/1669 [2:08:24<2:39:02, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 757/1669 [2:08:35<2:37:48, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 758/1669 [2:08:46<2:43:15, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  45%|████▌     | 759/1669 [2:08:58<2:46:49, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 760/1669 [2:09:07<2:37:50, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 761/1669 [2:09:18<2:42:47, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 762/1669 [2:09:30<2:44:27, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 763/1669 [2:09:41<2:47:01, 11.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 764/1669 [2:09:52<2:45:15, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 765/1669 [2:10:03<2:44:24, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 766/1669 [2:10:14<2:44:17, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 767/1669 [2:10:24<2:43:02, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 768/1669 [2:10:35<2:42:31, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 769/1669 [2:10:46<2:42:22, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 770/1669 [2:10:53<2:25:39,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▌     | 771/1669 [2:11:05<2:34:02, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▋     | 772/1669 [2:11:16<2:39:23, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▋     | 773/1669 [2:11:28<2:43:11, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▋     | 774/1669 [2:11:39<2:44:18, 11.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▋     | 775/1669 [2:11:49<2:40:19, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  46%|████▋     | 776/1669 [2:12:01<2:44:16, 11.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 777/1669 [2:12:12<2:46:35, 11.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 778/1669 [2:12:20<2:30:57, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 779/1669 [2:12:29<2:25:18,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 780/1669 [2:12:37<2:18:02,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 781/1669 [2:12:49<2:26:55,  9.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 782/1669 [2:13:00<2:31:23, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 783/1669 [2:13:07<2:21:02,  9.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 784/1669 [2:13:19<2:30:22, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 785/1669 [2:13:28<2:26:08,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 786/1669 [2:13:40<2:33:31, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 787/1669 [2:13:52<2:38:41, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 788/1669 [2:14:01<2:29:48, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 789/1669 [2:14:12<2:36:01, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 790/1669 [2:14:24<2:40:56, 10.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 791/1669 [2:14:33<2:32:16, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  47%|████▋     | 792/1669 [2:14:45<2:37:16, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 793/1669 [2:14:55<2:37:08, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 794/1669 [2:15:07<2:40:27, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 795/1669 [2:15:19<2:43:18, 11.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 796/1669 [2:15:30<2:44:44, 11.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 797/1669 [2:15:42<2:46:26, 11.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 798/1669 [2:15:54<2:47:00, 11.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 799/1669 [2:16:05<2:47:14, 11.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 800/1669 [2:16:16<2:41:47, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 801/1669 [2:16:24<2:28:07, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 802/1669 [2:16:32<2:21:50,  9.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 803/1669 [2:16:43<2:26:49, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 804/1669 [2:16:54<2:28:21, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 805/1669 [2:17:06<2:33:50, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 806/1669 [2:17:17<2:37:43, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 807/1669 [2:17:27<2:32:13, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 808/1669 [2:17:38<2:35:54, 10.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  48%|████▊     | 809/1669 [2:17:50<2:39:01, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▊     | 810/1669 [2:18:01<2:38:56, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▊     | 811/1669 [2:18:13<2:41:00, 11.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▊     | 812/1669 [2:18:24<2:39:28, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▊     | 813/1669 [2:18:35<2:37:36, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 814/1669 [2:18:45<2:36:13, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 815/1669 [2:18:56<2:35:46, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 816/1669 [2:19:07<2:34:54, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 817/1669 [2:19:18<2:34:38, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 818/1669 [2:19:28<2:31:11, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 819/1669 [2:19:37<2:22:53, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 820/1669 [2:19:48<2:28:27, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 821/1669 [2:20:00<2:32:43, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 822/1669 [2:20:10<2:30:09, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 823/1669 [2:20:20<2:27:12, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 824/1669 [2:20:29<2:19:19,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 825/1669 [2:20:38<2:16:02,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  49%|████▉     | 826/1669 [2:20:47<2:16:00,  9.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 827/1669 [2:20:59<2:23:32, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 828/1669 [2:21:11<2:29:25, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 829/1669 [2:21:21<2:30:04, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 830/1669 [2:21:33<2:33:58, 11.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 831/1669 [2:21:41<2:21:37, 10.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 832/1669 [2:21:49<2:10:14,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 833/1669 [2:21:59<2:12:09,  9.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|████▉     | 834/1669 [2:22:07<2:07:56,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 835/1669 [2:22:19<2:17:49,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 836/1669 [2:22:27<2:11:02,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 837/1669 [2:22:35<2:06:47,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 838/1669 [2:22:44<2:05:05,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 839/1669 [2:22:55<2:12:19,  9.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 840/1669 [2:23:05<2:15:03,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 841/1669 [2:23:16<2:17:17,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  50%|█████     | 842/1669 [2:23:24<2:10:43,  9.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 843/1669 [2:23:32<2:06:13,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 844/1669 [2:23:43<2:12:16,  9.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 845/1669 [2:23:54<2:16:09,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 846/1669 [2:24:04<2:18:53, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 847/1669 [2:24:14<2:16:35,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 848/1669 [2:24:20<2:01:42,  8.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 849/1669 [2:24:27<1:51:16,  8.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 850/1669 [2:24:33<1:44:14,  7.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 851/1669 [2:24:40<1:38:51,  7.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 852/1669 [2:24:46<1:35:37,  7.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 853/1669 [2:24:53<1:33:29,  6.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 854/1669 [2:25:03<1:48:54,  8.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████     | 855/1669 [2:25:14<1:59:51,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████▏    | 856/1669 [2:25:25<2:07:12,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████▏    | 857/1669 [2:25:35<2:12:32,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████▏    | 858/1669 [2:25:46<2:16:09, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  51%|█████▏    | 859/1669 [2:25:57<2:18:49, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 860/1669 [2:26:08<2:23:37, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 861/1669 [2:26:20<2:26:56, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 862/1669 [2:26:24<1:57:50,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 863/1669 [2:26:35<2:09:18,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 864/1669 [2:26:47<2:17:10, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 865/1669 [2:26:58<2:19:35, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 866/1669 [2:27:06<2:09:02,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 867/1669 [2:27:17<2:16:28, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 868/1669 [2:27:25<2:08:35,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 869/1669 [2:27:36<2:12:58,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 870/1669 [2:27:46<2:10:31,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 871/1669 [2:27:54<2:05:54,  9.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 872/1669 [2:28:06<2:14:08, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 873/1669 [2:28:15<2:11:43,  9.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 874/1669 [2:28:27<2:18:27, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 875/1669 [2:28:38<2:18:49, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  52%|█████▏    | 876/1669 [2:28:49<2:23:10, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 877/1669 [2:29:00<2:21:44, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 878/1669 [2:29:10<2:17:26, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 879/1669 [2:29:19<2:14:15, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 880/1669 [2:29:29<2:11:59, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 881/1669 [2:29:39<2:10:21,  9.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 882/1669 [2:29:48<2:09:19,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 883/1669 [2:29:58<2:08:31,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 884/1669 [2:30:09<2:11:50, 10.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 885/1669 [2:30:19<2:13:38, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 886/1669 [2:30:30<2:15:36, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 887/1669 [2:30:41<2:16:26, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 888/1669 [2:30:51<2:17:35, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 889/1669 [2:31:02<2:18:19, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 890/1669 [2:31:14<2:21:21, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 891/1669 [2:31:24<2:17:42, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  53%|█████▎    | 892/1669 [2:31:35<2:21:15, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▎    | 893/1669 [2:31:46<2:20:50, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▎    | 894/1669 [2:31:56<2:15:14, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▎    | 895/1669 [2:32:07<2:19:02, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▎    | 896/1669 [2:32:19<2:22:18, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▎    | 897/1669 [2:32:27<2:12:04, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 898/1669 [2:32:36<2:07:09,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 899/1669 [2:32:44<1:58:55,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 900/1669 [2:32:55<2:05:47,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 901/1669 [2:33:07<2:12:17, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 902/1669 [2:33:18<2:16:51, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 903/1669 [2:33:30<2:19:01, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 904/1669 [2:33:41<2:21:26, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 905/1669 [2:33:53<2:23:39, 11.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 906/1669 [2:34:04<2:21:49, 11.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 907/1669 [2:34:15<2:22:53, 11.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 908/1669 [2:34:25<2:18:59, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  54%|█████▍    | 909/1669 [2:34:35<2:12:03, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 910/1669 [2:34:44<2:06:01,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 911/1669 [2:34:52<1:58:26,  9.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 912/1669 [2:35:03<2:06:20, 10.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 913/1669 [2:35:14<2:11:05, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 914/1669 [2:35:26<2:15:31, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 915/1669 [2:35:34<2:03:57,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 916/1669 [2:35:42<1:56:45,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▍    | 917/1669 [2:35:53<2:04:36,  9.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 918/1669 [2:36:05<2:10:45, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 919/1669 [2:36:16<2:14:38, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 920/1669 [2:36:24<2:01:41,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 921/1669 [2:36:31<1:53:18,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 922/1669 [2:36:42<1:59:04,  9.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 923/1669 [2:36:51<1:56:26,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 924/1669 [2:37:02<2:03:59,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 925/1669 [2:37:13<2:05:58, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  55%|█████▌    | 926/1669 [2:37:20<1:56:29,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 927/1669 [2:37:28<1:49:32,  8.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 928/1669 [2:37:36<1:44:39,  8.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 929/1669 [2:37:43<1:40:57,  8.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 930/1669 [2:37:51<1:38:49,  8.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 931/1669 [2:37:58<1:37:08,  7.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 932/1669 [2:38:09<1:45:19,  8.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 933/1669 [2:38:18<1:48:25,  8.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 934/1669 [2:38:29<1:55:28,  9.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 935/1669 [2:38:38<1:56:20,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 936/1669 [2:38:47<1:50:43,  9.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 937/1669 [2:38:58<2:00:01,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▌    | 938/1669 [2:39:09<2:03:11, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▋    | 939/1669 [2:39:20<2:05:47, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▋    | 940/1669 [2:39:30<2:06:54, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▋    | 941/1669 [2:39:41<2:07:48, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  56%|█████▋    | 942/1669 [2:39:52<2:08:03, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 943/1669 [2:40:03<2:08:39, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 944/1669 [2:40:14<2:10:17, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 945/1669 [2:40:24<2:07:41, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 946/1669 [2:40:32<1:57:33,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 947/1669 [2:40:42<1:58:52,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 948/1669 [2:40:52<1:59:02,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 949/1669 [2:41:02<2:01:02, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 950/1669 [2:41:14<2:04:47, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 951/1669 [2:41:22<1:57:02,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 952/1669 [2:41:31<1:54:19,  9.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 953/1669 [2:41:43<2:01:44, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 954/1669 [2:41:54<2:06:04, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 955/1669 [2:42:06<2:09:30, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 956/1669 [2:42:10<1:44:27,  8.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 957/1669 [2:42:13<1:26:55,  7.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 958/1669 [2:42:17<1:14:23,  6.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  57%|█████▋    | 959/1669 [2:42:21<1:05:48,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 960/1669 [2:42:25<59:42,  5.05s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 961/1669 [2:42:29<56:08,  4.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 962/1669 [2:42:40<1:18:10,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 963/1669 [2:42:50<1:29:50,  7.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 964/1669 [2:43:00<1:37:32,  8.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 965/1669 [2:43:10<1:44:03,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 966/1669 [2:43:22<1:53:14,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 967/1669 [2:43:33<1:59:11, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 968/1669 [2:43:44<2:01:39, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 969/1669 [2:43:55<2:02:50, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 970/1669 [2:44:06<2:03:15, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 971/1669 [2:44:16<2:03:29, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 972/1669 [2:44:27<2:03:35, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 973/1669 [2:44:38<2:04:03, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 974/1669 [2:44:45<1:53:21,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 975/1669 [2:44:54<1:49:43,  9.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  58%|█████▊    | 976/1669 [2:45:06<1:56:57, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▊    | 977/1669 [2:45:17<2:01:38, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▊    | 978/1669 [2:45:27<1:57:36, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▊    | 979/1669 [2:45:38<2:02:00, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▊    | 980/1669 [2:45:49<2:01:36, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 981/1669 [2:45:57<1:54:08,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 982/1669 [2:46:06<1:49:02,  9.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 983/1669 [2:46:17<1:55:37, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 984/1669 [2:46:28<1:58:03, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 985/1669 [2:46:40<2:02:58, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 986/1669 [2:46:49<1:58:03, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 987/1669 [2:46:59<1:55:10, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 988/1669 [2:47:09<1:52:58,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 989/1669 [2:47:18<1:51:10,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 990/1669 [2:47:28<1:50:06,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 991/1669 [2:47:37<1:48:59,  9.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 992/1669 [2:47:48<1:52:28,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  59%|█████▉    | 993/1669 [2:47:57<1:49:01,  9.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 994/1669 [2:48:05<1:42:43,  9.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 995/1669 [2:48:15<1:45:48,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 996/1669 [2:48:26<1:52:47, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 997/1669 [2:48:37<1:56:43, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 998/1669 [2:48:49<2:00:49, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 999/1669 [2:49:01<2:03:10, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 1000/1669 [2:49:12<2:03:58, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|█████▉    | 1001/1669 [2:49:21<1:57:53, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1002/1669 [2:49:31<1:53:36, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1003/1669 [2:49:42<1:58:27, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1004/1669 [2:49:54<2:01:58, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1005/1669 [2:50:06<2:03:35, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1006/1669 [2:50:18<2:05:18, 11.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1007/1669 [2:50:29<2:06:16, 11.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1008/1669 [2:50:41<2:06:34, 11.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  60%|██████    | 1009/1669 [2:50:53<2:07:10, 11.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1010/1669 [2:51:04<2:06:54, 11.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1011/1669 [2:51:16<2:06:52, 11.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1012/1669 [2:51:24<1:55:00, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1013/1669 [2:51:33<1:51:19, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1014/1669 [2:51:43<1:51:02, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1015/1669 [2:51:53<1:49:33, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1016/1669 [2:52:05<1:54:46, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1017/1669 [2:52:13<1:45:40,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1018/1669 [2:52:21<1:41:13,  9.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1019/1669 [2:52:31<1:43:02,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1020/1669 [2:52:42<1:46:50,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1021/1669 [2:52:53<1:51:56, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████    | 1022/1669 [2:53:04<1:53:08, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████▏   | 1023/1669 [2:53:15<1:53:48, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████▏   | 1024/1669 [2:53:26<1:55:06, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████▏   | 1025/1669 [2:53:37<1:55:43, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  61%|██████▏   | 1026/1669 [2:53:48<1:55:45, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1027/1669 [2:53:58<1:55:52, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1028/1669 [2:54:10<1:58:14, 11.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1029/1669 [2:54:21<1:56:17, 10.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1030/1669 [2:54:29<1:49:02, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1031/1669 [2:54:41<1:53:30, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1032/1669 [2:54:52<1:55:02, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1033/1669 [2:55:04<1:57:08, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1034/1669 [2:55:13<1:51:37, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1035/1669 [2:55:24<1:51:45, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1036/1669 [2:55:33<1:47:21, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1037/1669 [2:55:45<1:51:57, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1038/1669 [2:55:54<1:48:44, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1039/1669 [2:56:06<1:52:30, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1040/1669 [2:56:14<1:44:43,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1041/1669 [2:56:22<1:39:02,  9.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1042/1669 [2:56:34<1:45:32, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  62%|██████▏   | 1043/1669 [2:56:44<1:44:06,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1044/1669 [2:56:55<1:49:17, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1045/1669 [2:57:07<1:51:58, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1046/1669 [2:57:18<1:54:30, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1047/1669 [2:57:30<1:56:00, 11.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1048/1669 [2:57:42<1:57:16, 11.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1049/1669 [2:57:53<1:57:32, 11.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1050/1669 [2:58:05<1:57:36, 11.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1051/1669 [2:58:15<1:54:34, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1052/1669 [2:58:23<1:45:14, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1053/1669 [2:58:31<1:37:38,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1054/1669 [2:58:39<1:32:35,  9.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1055/1669 [2:58:49<1:36:24,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1056/1669 [2:59:00<1:40:27,  9.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1057/1669 [2:59:11<1:43:25, 10.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1058/1669 [2:59:23<1:47:54, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  63%|██████▎   | 1059/1669 [2:59:30<1:38:31,  9.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▎   | 1060/1669 [2:59:38<1:33:14,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▎   | 1061/1669 [2:59:48<1:35:07,  9.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▎   | 1062/1669 [2:59:57<1:33:07,  9.20s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▎   | 1063/1669 [3:00:08<1:37:57,  9.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1064/1669 [3:00:18<1:40:56, 10.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1065/1669 [3:00:29<1:43:06, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1066/1669 [3:00:40<1:44:32, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1067/1669 [3:00:51<1:45:25, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1068/1669 [3:01:01<1:45:42, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1069/1669 [3:01:12<1:46:36, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1070/1669 [3:01:24<1:49:22, 10.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1071/1669 [3:01:32<1:39:32,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1072/1669 [3:01:41<1:36:15,  9.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1073/1669 [3:01:50<1:35:06,  9.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1074/1669 [3:02:01<1:38:15,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1075/1669 [3:02:12<1:41:19, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  64%|██████▍   | 1076/1669 [3:02:23<1:45:18, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1077/1669 [3:02:33<1:41:30, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1078/1669 [3:02:42<1:37:27,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1079/1669 [3:02:50<1:32:34,  9.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1080/1669 [3:03:02<1:39:02, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1081/1669 [3:03:13<1:43:07, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1082/1669 [3:03:22<1:36:38,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1083/1669 [3:03:32<1:36:53,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▍   | 1084/1669 [3:03:43<1:41:49, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1085/1669 [3:03:55<1:44:38, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1086/1669 [3:04:05<1:42:50, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1087/1669 [3:04:16<1:45:09, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1088/1669 [3:04:28<1:47:04, 11.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1089/1669 [3:04:36<1:38:09, 10.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1090/1669 [3:04:45<1:35:34,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1091/1669 [3:04:57<1:40:02, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1092/1669 [3:05:08<1:42:58, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  65%|██████▌   | 1093/1669 [3:05:20<1:45:23, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1094/1669 [3:05:31<1:44:31, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1095/1669 [3:05:41<1:43:16, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1096/1669 [3:05:52<1:42:55, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1097/1669 [3:06:03<1:42:27, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1098/1669 [3:06:13<1:42:31, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1099/1669 [3:06:24<1:42:22, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1100/1669 [3:06:33<1:36:31, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1101/1669 [3:06:42<1:32:48,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1102/1669 [3:06:51<1:29:51,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1103/1669 [3:07:00<1:27:51,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1104/1669 [3:07:08<1:26:19,  9.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▌   | 1105/1669 [3:07:17<1:25:31,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▋   | 1106/1669 [3:07:29<1:31:27,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▋   | 1107/1669 [3:07:40<1:36:27, 10.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▋   | 1108/1669 [3:07:52<1:39:28, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  66%|██████▋   | 1109/1669 [3:08:03<1:42:01, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1110/1669 [3:08:15<1:43:33, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1111/1669 [3:08:26<1:44:06, 11.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1112/1669 [3:08:38<1:45:00, 11.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1113/1669 [3:08:50<1:46:07, 11.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1114/1669 [3:09:01<1:45:40, 11.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1115/1669 [3:09:10<1:40:07, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1116/1669 [3:09:18<1:31:30,  9.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1117/1669 [3:09:30<1:35:35, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1118/1669 [3:09:38<1:29:44,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1119/1669 [3:09:47<1:28:04,  9.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1120/1669 [3:09:57<1:29:11,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1121/1669 [3:10:08<1:32:34, 10.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1122/1669 [3:10:17<1:28:34,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1123/1669 [3:10:28<1:31:29, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1124/1669 [3:10:36<1:24:54,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1125/1669 [3:10:47<1:30:30,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  67%|██████▋   | 1126/1669 [3:10:55<1:24:45,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1127/1669 [3:11:07<1:30:29, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1128/1669 [3:11:18<1:34:37, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1129/1669 [3:11:30<1:37:24, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1130/1669 [3:11:41<1:39:20, 11.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1131/1669 [3:11:50<1:32:41, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1132/1669 [3:11:59<1:28:06,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1133/1669 [3:12:10<1:32:29, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1134/1669 [3:12:22<1:35:06, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1135/1669 [3:12:33<1:35:47, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1136/1669 [3:12:42<1:32:00, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1137/1669 [3:12:51<1:26:52,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1138/1669 [3:13:01<1:27:35,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1139/1669 [3:13:09<1:24:03,  9.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1140/1669 [3:13:19<1:24:42,  9.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1141/1669 [3:13:31<1:30:01, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1142/1669 [3:13:41<1:31:01, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  68%|██████▊   | 1143/1669 [3:13:52<1:31:55, 10.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▊   | 1144/1669 [3:14:03<1:32:21, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▊   | 1145/1669 [3:14:14<1:33:03, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▊   | 1146/1669 [3:14:25<1:33:07, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▊   | 1147/1669 [3:14:35<1:33:00, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1148/1669 [3:14:45<1:30:28, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1149/1669 [3:14:55<1:28:37, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1150/1669 [3:15:05<1:27:42, 10.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1151/1669 [3:15:15<1:26:47, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1152/1669 [3:15:25<1:26:11, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1153/1669 [3:15:34<1:25:38,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1154/1669 [3:15:45<1:28:05, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1155/1669 [3:15:57<1:31:31, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1156/1669 [3:16:09<1:33:35, 10.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1157/1669 [3:16:18<1:28:56, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1158/1669 [3:16:28<1:27:23, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  69%|██████▉   | 1159/1669 [3:16:39<1:29:40, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1160/1669 [3:16:49<1:27:23, 10.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1161/1669 [3:17:00<1:29:07, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1162/1669 [3:17:11<1:31:57, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1163/1669 [3:17:22<1:31:25, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1164/1669 [3:17:32<1:27:36, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1165/1669 [3:17:42<1:27:51, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1166/1669 [3:17:50<1:21:49,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1167/1669 [3:18:00<1:20:35,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|██████▉   | 1168/1669 [3:18:09<1:18:49,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1169/1669 [3:18:20<1:22:58,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1170/1669 [3:18:30<1:24:11, 10.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1171/1669 [3:18:42<1:27:34, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1172/1669 [3:18:50<1:20:45,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1173/1669 [3:18:58<1:17:26,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1174/1669 [3:19:09<1:20:09,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1175/1669 [3:19:20<1:24:43, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  70%|███████   | 1176/1669 [3:19:29<1:21:17,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1177/1669 [3:19:40<1:22:06, 10.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1178/1669 [3:19:50<1:23:36, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1179/1669 [3:20:01<1:24:43, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1180/1669 [3:20:12<1:25:19, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1181/1669 [3:20:22<1:25:38, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1182/1669 [3:20:33<1:25:52, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1183/1669 [3:20:44<1:26:03, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1184/1669 [3:20:54<1:25:59, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1185/1669 [3:21:05<1:26:06, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1186/1669 [3:21:16<1:25:51, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1187/1669 [3:21:27<1:25:54, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1188/1669 [3:21:37<1:25:56, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████   | 1189/1669 [3:21:48<1:25:37, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████▏  | 1190/1669 [3:21:56<1:18:56,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████▏  | 1191/1669 [3:22:08<1:23:00, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████▏  | 1192/1669 [3:22:15<1:16:01,  9.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  71%|███████▏  | 1193/1669 [3:22:25<1:17:14,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1194/1669 [3:22:37<1:21:19, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1195/1669 [3:22:47<1:20:13, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1196/1669 [3:22:58<1:22:39, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1197/1669 [3:23:08<1:21:24, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1198/1669 [3:23:17<1:17:31,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1199/1669 [3:23:28<1:20:49, 10.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1200/1669 [3:23:40<1:23:32, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1201/1669 [3:23:49<1:19:56, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1202/1669 [3:23:57<1:14:53,  9.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1203/1669 [3:24:07<1:16:23,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1204/1669 [3:24:16<1:13:09,  9.44s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1205/1669 [3:24:26<1:14:03,  9.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1206/1669 [3:24:37<1:18:30, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1207/1669 [3:24:49<1:21:11, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1208/1669 [3:24:59<1:20:20, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1209/1669 [3:25:11<1:22:36, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  72%|███████▏  | 1210/1669 [3:25:20<1:18:06, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1211/1669 [3:25:31<1:19:48, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1212/1669 [3:25:41<1:19:38, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1213/1669 [3:25:52<1:21:32, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1214/1669 [3:26:00<1:13:59,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1215/1669 [3:26:07<1:07:46,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1216/1669 [3:26:18<1:11:33,  9.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1217/1669 [3:26:29<1:16:32, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1218/1669 [3:26:40<1:17:14, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1219/1669 [3:26:50<1:15:49, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1220/1669 [3:27:01<1:18:57, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1221/1669 [3:27:12<1:20:01, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1222/1669 [3:27:24<1:22:02, 11.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1223/1669 [3:27:34<1:20:15, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1224/1669 [3:27:45<1:19:23, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1225/1669 [3:27:56<1:20:44, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  73%|███████▎  | 1226/1669 [3:28:08<1:22:06, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▎  | 1227/1669 [3:28:16<1:14:29, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▎  | 1228/1669 [3:28:27<1:17:44, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▎  | 1229/1669 [3:28:35<1:11:39,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▎  | 1230/1669 [3:28:46<1:14:06, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1231/1669 [3:28:58<1:16:57, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1232/1669 [3:29:09<1:18:50, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1233/1669 [3:29:18<1:13:31, 10.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1234/1669 [3:29:26<1:10:28,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1235/1669 [3:29:37<1:12:18, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1236/1669 [3:29:49<1:15:45, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1237/1669 [3:30:00<1:16:47, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1238/1669 [3:30:10<1:16:44, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1239/1669 [3:30:21<1:17:01, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1240/1669 [3:30:32<1:16:37, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1241/1669 [3:30:43<1:16:46, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1242/1669 [3:30:53<1:16:15, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  74%|███████▍  | 1243/1669 [3:31:04<1:15:51, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1244/1669 [3:31:16<1:17:30, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1245/1669 [3:31:26<1:16:22, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1246/1669 [3:31:34<1:10:13,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1247/1669 [3:31:44<1:09:06,  9.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1248/1669 [3:31:55<1:12:38, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1249/1669 [3:32:07<1:15:07, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1250/1669 [3:32:15<1:09:24,  9.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▍  | 1251/1669 [3:32:24<1:06:25,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1252/1669 [3:32:35<1:09:54, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1253/1669 [3:32:43<1:05:55,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1254/1669 [3:32:53<1:07:31,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1255/1669 [3:33:02<1:05:05,  9.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1256/1669 [3:33:13<1:07:39,  9.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1257/1669 [3:33:23<1:07:58,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1258/1669 [3:33:31<1:05:01,  9.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1259/1669 [3:33:40<1:04:00,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  75%|███████▌  | 1260/1669 [3:33:50<1:03:52,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1261/1669 [3:34:01<1:07:32,  9.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1262/1669 [3:34:10<1:05:59,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1263/1669 [3:34:19<1:04:11,  9.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1264/1669 [3:34:28<1:03:11,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1265/1669 [3:34:40<1:07:30, 10.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1266/1669 [3:34:51<1:10:15, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1267/1669 [3:35:02<1:09:48, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1268/1669 [3:35:13<1:10:25, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1269/1669 [3:35:23<1:10:53, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1270/1669 [3:35:34<1:11:02, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1271/1669 [3:35:45<1:10:55, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▌  | 1272/1669 [3:35:56<1:10:46, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▋  | 1273/1669 [3:36:06<1:10:32, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▋  | 1274/1669 [3:36:17<1:10:27, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▋  | 1275/1669 [3:36:28<1:10:27, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  76%|███████▋  | 1276/1669 [3:36:39<1:10:32, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1277/1669 [3:36:50<1:10:29, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1278/1669 [3:37:00<1:10:34, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1279/1669 [3:37:11<1:10:11, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1280/1669 [3:37:22<1:10:45, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1281/1669 [3:37:34<1:11:50, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1282/1669 [3:37:46<1:12:41, 11.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1283/1669 [3:37:57<1:13:06, 11.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1284/1669 [3:38:09<1:13:08, 11.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1285/1669 [3:38:19<1:10:59, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1286/1669 [3:38:31<1:12:07, 11.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1287/1669 [3:38:42<1:12:18, 11.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1288/1669 [3:38:54<1:12:28, 11.41s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1289/1669 [3:39:05<1:12:30, 11.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1290/1669 [3:39:16<1:10:40, 11.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1291/1669 [3:39:27<1:11:11, 11.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1292/1669 [3:39:39<1:11:31, 11.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  77%|███████▋  | 1293/1669 [3:39:51<1:11:53, 11.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1294/1669 [3:40:02<1:11:48, 11.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1295/1669 [3:40:14<1:11:46, 11.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1296/1669 [3:40:25<1:10:58, 11.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1297/1669 [3:40:37<1:11:03, 11.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1298/1669 [3:40:47<1:07:59, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1299/1669 [3:40:55<1:03:04, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1300/1669 [3:41:03<58:52,  9.57s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1301/1669 [3:41:14<1:00:29,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1302/1669 [3:41:24<1:00:57,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1303/1669 [3:41:35<1:03:32, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1304/1669 [3:41:47<1:05:30, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1305/1669 [3:41:58<1:06:42, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1306/1669 [3:42:09<1:05:50, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1307/1669 [3:42:20<1:05:48, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1308/1669 [3:42:31<1:06:39, 11.08s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1309/1669 [3:42:43<1:07:04, 11.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  78%|███████▊  | 1310/1669 [3:42:54<1:06:53, 11.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▊  | 1311/1669 [3:43:05<1:07:12, 11.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▊  | 1312/1669 [3:43:14<1:02:03, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▊  | 1313/1669 [3:43:23<59:25, 10.02s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▊  | 1314/1669 [3:43:34<1:01:53, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1315/1669 [3:43:46<1:04:08, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1316/1669 [3:43:58<1:05:24, 11.12s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1317/1669 [3:44:06<1:00:13, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1318/1669 [3:44:14<56:20,  9.63s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1319/1669 [3:44:24<56:36,  9.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1320/1669 [3:44:35<59:02, 10.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1321/1669 [3:44:47<1:01:27, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1322/1669 [3:44:56<58:29, 10.12s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1323/1669 [3:45:05<55:35,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1324/1669 [3:45:15<57:13,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1325/1669 [3:45:26<58:35, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  79%|███████▉  | 1326/1669 [3:45:36<58:23, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1327/1669 [3:45:48<59:54, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1328/1669 [3:45:58<1:00:05, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1329/1669 [3:46:09<59:55, 10.57s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1330/1669 [3:46:20<1:00:17, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1331/1669 [3:46:30<1:00:10, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1332/1669 [3:46:41<59:44, 10.64s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1333/1669 [3:46:52<59:36, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1334/1669 [3:47:02<59:44, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|███████▉  | 1335/1669 [3:47:13<59:25, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1336/1669 [3:47:24<59:36, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1337/1669 [3:47:35<59:38, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1338/1669 [3:47:46<1:00:05, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1339/1669 [3:47:57<1:00:02, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1340/1669 [3:48:08<59:51, 10.92s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1341/1669 [3:48:19<59:33, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1342/1669 [3:48:30<1:00:07, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  80%|████████  | 1343/1669 [3:48:41<59:46, 11.00s/it]  Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1344/1669 [3:48:52<59:07, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1345/1669 [3:49:02<58:31, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1346/1669 [3:49:13<58:13, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1347/1669 [3:49:24<57:43, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1348/1669 [3:49:35<57:30, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1349/1669 [3:49:45<57:05, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1350/1669 [3:49:56<57:15, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1351/1669 [3:50:07<56:51, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1352/1669 [3:50:17<55:38, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1353/1669 [3:50:26<54:07, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1354/1669 [3:50:38<55:53, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1355/1669 [3:50:48<55:29, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████  | 1356/1669 [3:51:00<56:46, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████▏ | 1357/1669 [3:51:11<56:53, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████▏ | 1358/1669 [3:51:22<56:36, 10.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████▏ | 1359/1669 [3:51:33<56:15, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  81%|████████▏ | 1360/1669 [3:51:43<55:47, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1361/1669 [3:51:54<55:22, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1362/1669 [3:52:05<54:57, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1363/1669 [3:52:15<54:46, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1364/1669 [3:52:27<55:38, 10.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1365/1669 [3:52:35<51:00, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1366/1669 [3:52:43<48:15,  9.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1367/1669 [3:52:54<49:23,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1368/1669 [3:53:03<48:23,  9.64s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1369/1669 [3:53:14<50:51, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1370/1669 [3:53:26<52:41, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1371/1669 [3:53:37<53:55, 10.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1372/1669 [3:53:49<54:39, 11.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1373/1669 [3:54:00<55:00, 11.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1374/1669 [3:54:10<52:48, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1375/1669 [3:54:22<53:51, 10.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  82%|████████▏ | 1376/1669 [3:54:29<48:26,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1377/1669 [3:54:37<45:25,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1378/1669 [3:54:48<48:07,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1379/1669 [3:55:00<50:06, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1380/1669 [3:55:09<48:03,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1381/1669 [3:55:20<49:53, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1382/1669 [3:55:31<50:05, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1383/1669 [3:55:42<50:45, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1384/1669 [3:55:53<50:41, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1385/1669 [3:56:03<50:34, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1386/1669 [3:56:14<50:27, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1387/1669 [3:56:25<50:36, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1388/1669 [3:56:33<46:55, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1389/1669 [3:56:42<44:24,  9.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1390/1669 [3:56:50<42:51,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1391/1669 [3:56:59<41:53,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1392/1669 [3:57:08<41:31,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  83%|████████▎ | 1393/1669 [3:57:16<41:04,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▎ | 1394/1669 [3:57:27<43:34,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▎ | 1395/1669 [3:57:40<47:29, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▎ | 1396/1669 [3:57:50<47:45, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▎ | 1397/1669 [3:58:03<49:40, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1398/1669 [3:58:11<46:26, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1399/1669 [3:58:23<47:58, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1400/1669 [3:58:34<48:16, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1401/1669 [3:58:45<49:03, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1402/1669 [3:58:53<44:21,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1403/1669 [3:59:03<43:56,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1404/1669 [3:59:12<43:15,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1405/1669 [3:59:24<45:10, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1406/1669 [3:59:34<44:54, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1407/1669 [3:59:43<43:54, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1408/1669 [3:59:53<43:18,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1409/1669 [4:00:04<44:35, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  84%|████████▍ | 1410/1669 [4:00:16<46:33, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1411/1669 [4:00:30<49:55, 11.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1412/1669 [4:00:38<45:52, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1413/1669 [4:00:48<45:03, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1414/1669 [4:00:58<44:12, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1415/1669 [4:01:07<42:07,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1416/1669 [4:01:19<43:31, 10.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1417/1669 [4:01:30<45:05, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▍ | 1418/1669 [4:01:38<40:59,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1419/1669 [4:01:47<39:28,  9.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1420/1669 [4:01:56<39:05,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1421/1669 [4:02:07<41:23, 10.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1422/1669 [4:02:18<42:17, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1423/1669 [4:02:27<40:56,  9.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1424/1669 [4:02:36<39:27,  9.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1425/1669 [4:02:45<38:18,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  85%|████████▌ | 1426/1669 [4:02:54<37:19,  9.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1427/1669 [4:03:02<36:07,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1428/1669 [4:03:11<35:44,  8.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1429/1669 [4:03:21<36:21,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1430/1669 [4:03:32<39:01,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1431/1669 [4:03:43<40:48, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1432/1669 [4:03:51<36:47,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1433/1669 [4:03:59<35:44,  9.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1434/1669 [4:04:10<38:16,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1435/1669 [4:04:22<40:34, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1436/1669 [4:04:32<39:14, 10.11s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1437/1669 [4:04:42<39:43, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1438/1669 [4:04:51<37:05,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▌ | 1439/1669 [4:05:03<40:15, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▋ | 1440/1669 [4:05:12<38:18, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▋ | 1441/1669 [4:05:23<38:44, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▋ | 1442/1669 [4:05:31<37:01,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  86%|████████▋ | 1443/1669 [4:05:40<35:53,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1444/1669 [4:05:49<35:16,  9.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1445/1669 [4:06:01<37:24, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1446/1669 [4:06:12<38:25, 10.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1447/1669 [4:06:24<39:38, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1448/1669 [4:06:33<38:11, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1449/1669 [4:06:41<35:19,  9.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1450/1669 [4:06:49<33:23,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1451/1669 [4:07:01<35:51,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1452/1669 [4:07:12<37:36, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1453/1669 [4:07:24<38:24, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1454/1669 [4:07:33<36:46, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1455/1669 [4:07:41<34:43,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1456/1669 [4:07:50<33:50,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1457/1669 [4:08:01<34:22,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1458/1669 [4:08:08<32:11,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1459/1669 [4:08:20<34:25,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  87%|████████▋ | 1460/1669 [4:08:30<34:18,  9.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1461/1669 [4:08:39<33:57,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1462/1669 [4:08:49<33:41,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1463/1669 [4:08:59<33:26,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1464/1669 [4:09:09<33:19,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1465/1669 [4:09:18<33:09,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1466/1669 [4:09:29<33:53, 10.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1467/1669 [4:09:40<34:23, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1468/1669 [4:09:50<34:37, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1469/1669 [4:10:01<34:46, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1470/1669 [4:10:12<34:50, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1471/1669 [4:10:22<34:49, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1472/1669 [4:10:33<34:37, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1473/1669 [4:10:41<32:21,  9.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1474/1669 [4:10:50<30:54,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1475/1669 [4:11:01<32:26, 10.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1476/1669 [4:11:12<33:30, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  88%|████████▊ | 1477/1669 [4:11:24<34:22, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▊ | 1478/1669 [4:11:35<35:00, 11.00s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▊ | 1479/1669 [4:11:43<31:15,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▊ | 1480/1669 [4:11:52<30:25,  9.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▊ | 1481/1669 [4:12:01<29:39,  9.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1482/1669 [4:12:09<28:13,  9.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1483/1669 [4:12:20<29:33,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1484/1669 [4:12:29<29:22,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1485/1669 [4:12:38<28:39,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1486/1669 [4:12:47<28:08,  9.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1487/1669 [4:12:58<29:59,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1488/1669 [4:13:10<31:17, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1489/1669 [4:13:21<32:07, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1490/1669 [4:13:33<32:39, 10.95s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1491/1669 [4:13:42<30:38, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1492/1669 [4:13:50<28:43,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  89%|████████▉ | 1493/1669 [4:14:02<30:04, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1494/1669 [4:14:13<30:46, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1495/1669 [4:14:24<31:23, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1496/1669 [4:14:33<29:36, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1497/1669 [4:14:44<29:29, 10.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1498/1669 [4:14:55<30:13, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1499/1669 [4:15:04<28:52, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1500/1669 [4:15:12<26:31,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1501/1669 [4:15:21<26:30,  9.47s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|████████▉ | 1502/1669 [4:15:33<28:05, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1503/1669 [4:15:45<29:09, 10.54s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1504/1669 [4:15:56<29:48, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1505/1669 [4:16:05<28:02, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1506/1669 [4:16:15<27:15, 10.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1507/1669 [4:16:24<26:23,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1508/1669 [4:16:33<26:06,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1509/1669 [4:16:45<27:29, 10.31s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  90%|█████████ | 1510/1669 [4:16:54<26:23,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1511/1669 [4:17:06<27:30, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1512/1669 [4:17:16<27:27, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1513/1669 [4:17:26<26:32, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1514/1669 [4:17:38<27:32, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1515/1669 [4:17:49<27:48, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1516/1669 [4:18:00<27:31, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1517/1669 [4:18:11<27:57, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1518/1669 [4:18:22<27:43, 11.02s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1519/1669 [4:18:34<27:53, 11.16s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1520/1669 [4:18:45<27:58, 11.26s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1521/1669 [4:18:57<28:00, 11.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████ | 1522/1669 [4:19:06<26:13, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████▏| 1523/1669 [4:19:15<24:56, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████▏| 1524/1669 [4:19:27<25:49, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████▏| 1525/1669 [4:19:38<26:20, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████▏| 1526/1669 [4:19:49<25:56, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  91%|█████████▏| 1527/1669 [4:20:00<25:41, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1528/1669 [4:20:11<25:24, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1529/1669 [4:20:21<25:08, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1530/1669 [4:20:32<25:00, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1531/1669 [4:20:43<24:50, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1532/1669 [4:20:51<22:44,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1533/1669 [4:20:59<21:03,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1534/1669 [4:21:07<20:09,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1535/1669 [4:21:19<21:55,  9.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1536/1669 [4:21:29<21:59,  9.92s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1537/1669 [4:21:38<21:39,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1538/1669 [4:21:42<17:24,  7.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1539/1669 [4:21:53<19:01,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1540/1669 [4:22:03<20:08,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1541/1669 [4:22:14<20:52,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1542/1669 [4:22:25<21:21, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  92%|█████████▏| 1543/1669 [4:22:36<21:41, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1544/1669 [4:22:44<20:20,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1545/1669 [4:22:53<19:29,  9.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1546/1669 [4:23:02<18:49,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1547/1669 [4:23:10<18:22,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1548/1669 [4:23:19<18:04,  8.96s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1549/1669 [4:23:28<17:43,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1550/1669 [4:23:36<17:05,  8.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1551/1669 [4:23:47<18:39,  9.48s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1552/1669 [4:23:59<19:51, 10.18s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1553/1669 [4:24:11<20:28, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1554/1669 [4:24:20<19:24, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1555/1669 [4:24:31<19:56, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1556/1669 [4:24:42<20:00, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1557/1669 [4:24:53<19:54, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1558/1669 [4:25:03<19:46, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1559/1669 [4:25:14<19:38, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  93%|█████████▎| 1560/1669 [4:25:25<19:26, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▎| 1561/1669 [4:25:36<19:15, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▎| 1562/1669 [4:25:46<19:07, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▎| 1563/1669 [4:25:57<18:56, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▎| 1564/1669 [4:26:08<18:42, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1565/1669 [4:26:19<18:34, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1566/1669 [4:26:29<18:27, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1567/1669 [4:26:40<18:18, 10.77s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1568/1669 [4:26:48<16:39,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1569/1669 [4:26:56<15:36,  9.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1570/1669 [4:27:05<15:20,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1571/1669 [4:27:16<16:06,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1572/1669 [4:27:28<16:44, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1573/1669 [4:27:38<16:38, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1574/1669 [4:27:50<17:01, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1575/1669 [4:28:00<16:41, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1576/1669 [4:28:11<16:32, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  94%|█████████▍| 1577/1669 [4:28:20<15:23, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1578/1669 [4:28:31<15:57, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1579/1669 [4:28:42<15:54, 10.60s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1580/1669 [4:28:53<15:42, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1581/1669 [4:29:01<14:28,  9.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1582/1669 [4:29:12<14:40, 10.13s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1583/1669 [4:29:22<14:38, 10.22s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1584/1669 [4:29:34<15:02, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▍| 1585/1669 [4:29:45<15:17, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1586/1669 [4:29:57<15:15, 11.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1587/1669 [4:30:07<14:54, 10.91s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1588/1669 [4:30:18<14:40, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1589/1669 [4:30:29<14:28, 10.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1590/1669 [4:30:40<14:17, 10.86s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1591/1669 [4:30:50<14:02, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1592/1669 [4:31:01<13:48, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  95%|█████████▌| 1593/1669 [4:31:12<13:35, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1594/1669 [4:31:22<13:27, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1595/1669 [4:31:33<13:14, 10.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1596/1669 [4:31:44<13:02, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1597/1669 [4:31:54<12:49, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1598/1669 [4:32:03<12:00, 10.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1599/1669 [4:32:15<12:18, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1600/1669 [4:32:26<12:27, 10.84s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1601/1669 [4:32:34<11:18,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1602/1669 [4:32:44<11:05,  9.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1603/1669 [4:32:56<11:26, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1604/1669 [4:33:06<11:23, 10.51s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1605/1669 [4:33:15<10:28,  9.82s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▌| 1606/1669 [4:33:23<09:45,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▋| 1607/1669 [4:33:34<10:18,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▋| 1608/1669 [4:33:45<10:32, 10.36s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▋| 1609/1669 [4:33:56<10:33, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  96%|█████████▋| 1610/1669 [4:34:08<10:34, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1611/1669 [4:34:18<10:12, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1612/1669 [4:34:29<10:17, 10.83s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1613/1669 [4:34:37<09:20, 10.01s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1614/1669 [4:34:46<08:42,  9.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1615/1669 [4:34:56<08:45,  9.73s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1616/1669 [4:35:05<08:23,  9.50s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1617/1669 [4:35:13<07:55,  9.15s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1618/1669 [4:35:25<08:23,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1619/1669 [4:35:32<07:37,  9.14s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1620/1669 [4:35:43<07:57,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1621/1669 [4:35:52<07:28,  9.34s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1622/1669 [4:36:03<07:40,  9.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1623/1669 [4:36:13<07:42, 10.04s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1624/1669 [4:36:20<06:53,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1625/1669 [4:36:28<06:24,  8.74s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1626/1669 [4:36:39<06:40,  9.32s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  97%|█████████▋| 1627/1669 [4:36:46<06:10,  8.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1628/1669 [4:36:57<06:23,  9.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1629/1669 [4:37:08<06:28,  9.71s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1630/1669 [4:37:18<06:31, 10.05s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1631/1669 [4:37:29<06:28, 10.23s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1632/1669 [4:37:40<06:24, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1633/1669 [4:37:50<06:15, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1634/1669 [4:38:01<06:08, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1635/1669 [4:38:12<05:59, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1636/1669 [4:38:23<05:50, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1637/1669 [4:38:33<05:41, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1638/1669 [4:38:44<05:34, 10.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1639/1669 [4:38:56<05:28, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1640/1669 [4:39:08<05:29, 11.37s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1641/1669 [4:39:20<05:22, 11.52s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1642/1669 [4:39:29<04:51, 10.81s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  98%|█████████▊| 1643/1669 [4:39:39<04:32, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▊| 1644/1669 [4:39:49<04:21, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▊| 1645/1669 [4:40:00<04:12, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▊| 1646/1669 [4:40:11<04:02, 10.56s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▊| 1647/1669 [4:40:21<03:54, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▊| 1648/1669 [4:40:32<03:44, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1649/1669 [4:40:43<03:33, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1650/1669 [4:40:54<03:23, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1651/1669 [4:41:04<03:13, 10.76s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1652/1669 [4:41:16<03:06, 10.99s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1653/1669 [4:41:28<02:58, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1654/1669 [4:41:39<02:48, 11.27s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1655/1669 [4:41:51<02:38, 11.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1656/1669 [4:42:01<02:24, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1657/1669 [4:42:12<02:11, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1658/1669 [4:42:22<01:58, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1659/1669 [4:42:34<01:50, 11.06s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating:  99%|█████████▉| 1660/1669 [4:42:43<01:33, 10.35s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1661/1669 [4:42:51<01:17,  9.68s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1662/1669 [4:43:02<01:11, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1663/1669 [4:43:14<01:03, 10.65s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1664/1669 [4:43:22<00:48,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1665/1669 [4:43:31<00:38,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1666/1669 [4:43:42<00:30, 10.03s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1667/1669 [4:43:51<00:19,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|█████████▉| 1668/1669 [4:44:01<00:09,  9.97s/it]Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n",
      "Evaluating: 100%|██████████| 1669/1669 [4:44:13<00:00, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EM: 0.00\n",
      "F1: 46.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "em_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "subset_dataset = tokenized_test_dataset\n",
    "lora_model.eval()\n",
    "\n",
    "for i in tqdm(range(len(subset_dataset)), desc=\"Evaluating\"):\n",
    "    sample = subset_dataset[i]\n",
    "\n",
    "    input_ids = torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(sample[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = lora_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    pred_str = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Gold label: decode from true token IDs without -100\n",
    "    if \"labels\" in sample:\n",
    "        label = np.array(sample[\"labels\"])\n",
    "        label = label[label != -100]\n",
    "        label_str = tokenizer.decode(label, skip_special_tokens=True)\n",
    "    else:\n",
    "        label_str = sample[\"answer\"]    # fallback if using original dataset\n",
    "\n",
    "    em = compute_exact(pred_str, label_str)\n",
    "    f1 = compute_f1(pred_str, label_str)\n",
    "\n",
    "    em_scores.append(em)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"\\nEM: {100 * np.mean(em_scores):.2f}\")\n",
    "print(f\"F1: {100 * np.mean(f1_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7b4ce",
   "metadata": {},
   "source": [
    "### Test prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6320f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Answer ===\n",
      "\n",
      "\n",
      "In 2019, the total stock-based compensation expense decreased by $344 compared to 2018. The expense related to unvested employee stock options decreased by $175, while the expense related to unvested RSUs increased by $174.\n",
      "\n",
      "Recommendation:\n",
      "It is essential to monitor the trends in stock-based compensation expenses and the number of unvested employee stock options and RSUs to make informed decisions about the company's compensation strategy.\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "\n",
    "markdown_table = \"\"\"|  | Year Ended | Year Ended |\n",
    "| Stock-Based Compensation by Type of Award | December 31, 2019 | December 31, 2018 |\n",
    "| Stock options | $2,756 | $2,926 |\n",
    "| RSUs | 955 | 1,129 |\n",
    "| Total stock-based compensation expense | $3,711 | $4,055 |\"\"\"\n",
    "\n",
    "test_prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer's scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`\n",
    "\n",
    "Table:\n",
    "{markdown_table}\n",
    "\n",
    "Context:\n",
    "Stock-based compensation expense is included in general and administrative expense for each period as follows:\n",
    "As of December 31, 2019, there was $4,801 of unrecognized stock-based compensation expense related to unvested employee stock options and $1,882 of unrecognized stock-based compensation expense related to unvested RSUs. These costs are expected to be recognized over a weighted-average period of 2.13 and 2.33 years, respectively.\n",
    "\n",
    "Question:\n",
    "Based on data, what insights that we can get?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_tokens = outputs[0][input_length:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== Generated Answer ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ada60aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Answer ===\n",
      "\n",
      "\n",
      "The total stock-based compensation expense decreased from $4,055 in 2018 to $3,711 in 2019. This suggests that the company may be focusing on cost efficiency and potentially reducing employee incentives.\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "\n",
    "markdown_table = \"\"\"|  | Year Ended | Year Ended |\n",
    "| Stock-Based Compensation by Type of Award | December 31, 2019 | December 31, 2018 |\n",
    "| Stock options | $2,756 | $2,926 |\n",
    "| RSUs | 955 | 1,129 |\n",
    "| Total stock-based compensation expense | $3,711 | $4,055 |\"\"\"\n",
    "\n",
    "test_prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer's scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`\n",
    "\n",
    "Table:\n",
    "{markdown_table}\n",
    "\n",
    "Context:\n",
    "The table provides a comparison of stock-based compensation expenses for PT XYZ across two consecutive years. The data reveals how different award types contributed to the overall compensation and helps assess year-over-year cost efficiency and employee incentives.\n",
    "\n",
    "Question:\n",
    "How did the total stock-based compensation expense change from 2018 to 2019, and what does that suggest about the company’s strategy toward talent retention?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_tokens = outputs[0][input_length:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== Generated Answer ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "40cc760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Answer ===\n",
      "\n",
      "\n",
      "Stock options show a greater year-over-year cost reduction. The company could consider issuing more RSUs to employees to reduce the overall cost of stock-based compensation.\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "\n",
    "markdown_table = \"\"\"|  | Year Ended | Year Ended |\n",
    "| Stock-Based Compensation by Type of Award | December 31, 2019 | December 31, 2018 |\n",
    "| Stock options | $2,756 | $2,926 |\n",
    "| RSUs | 955 | 1,129 |\n",
    "| Total stock-based compensation expense | $3,711 | $4,055 |\"\"\"\n",
    "\n",
    "test_prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer's scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`\n",
    "\n",
    "Table:\n",
    "{markdown_table}\n",
    "\n",
    "Context:\n",
    "\n",
    "Question:\n",
    "Between stock options and RSUs, which component shows a greater year-over-year cost reduction, and what strategic decision could the company make based on this data?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_tokens = outputs[0][input_length:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== Generated Answer ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "abbffd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Answer ===\n",
      "\n",
      "\n",
      "Tidak ada indikasi yang signifikan bahwa perusahaan berhasil menekan biaya kompensasi. Biaya kompensasi berbasis saham pada tahun 2019 mencapai $3,711, naik dibandingkan dengan tahun 2018 yang hanya $4,055. Komponen yang paling berkontribusi terhadap penurunan biaya adalah RSUs dengan jumlah 955 pada tahun 2019, lebih rendah dibandingkan dengan 1,129 pada tahun 2018. Namun, komponen stock options menunjukkan penurunan dari $2,926 pada tahun 2018 menjadi $2,756 pada tahun 2019.\n",
      "\n",
      "Scale: none\n",
      "\n",
      "Action:\n",
      "Perusahaan harus melakukan analisis lebih dalam terhadap data ini dan mengidentifikasi alasan kesalahan yang mengakibatkan penurunan biaya kompensasi. Selain itu, perusahaan harus mempertimbangkan alasan yang lain seperti kualitas karyawan dan kinerja perusahaan dalam memutuskan apakah perlu mengurangi biaya kompensasi atau tidak.\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "\n",
    "markdown_table = \"\"\"|  | Year Ended | Year Ended |\n",
    "| Stock-Based Compensation by Type of Award | December 31, 2019 | December 31, 2018 |\n",
    "| Stock options | $2,756 | $2,926 |\n",
    "| RSUs | 955 | 1,129 |\n",
    "| Total stock-based compensation expense | $3,711 | $4,055 |\"\"\"\n",
    "\n",
    "test_prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer's scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`\n",
    "\n",
    "Table:\n",
    "{markdown_table}\n",
    "\n",
    "Context:\n",
    "Tabel berikut menunjukkan rincian biaya kompensasi berbasis saham PT ABC selama dua tahun terakhir. Perusahaan sedang meninjau kembali efektivitas alokasi insentif karyawan dalam kaitannya dengan efisiensi operasional dan keberlanjutan biaya.\n",
    "\n",
    "Question:\n",
    "Dari data tersebut, apakah terdapat indikasi bahwa perusahaan berhasil menekan biaya kompensasi? Jelaskan alasan dan komponen yang paling berkontribusi terhadap penurunan atau peningkatan biaya.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_tokens = outputs[0][input_length:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== Generated Answer ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0ca6844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Answer ===\n",
      "\n",
      "\n",
      "{ assistant\n",
      "question_type: Comparison\n",
      "evidence: [\"Opsi saham: Rp2.450\", \"Saham terbatas (RSU): Rp1.100\", \"Opsi saham: Rp2.800\", \"Saham terbatas (RSU): Rp1.300\", \"Total kompensasi berbasis saham: Rp3.550\", \"Total kompensasi berbasis saham: Rp4.100\"]\n",
      "equation: N.A.\n",
      "answer: \n",
      "- Mempertahankan: 31 Desember 2023 (Rp2.450) dan 31 Desember 2022 (Rp2.800)\n",
      "- Menambah: 31 Desember 2023 (Rp1.100) dan 31 Desember 2022 (Rp1.300)\n",
      "- Mengurangi: N.A.\n",
      "scale: none\n",
      "action: Perusahaan sebaiknya mempertimbangkan faktor-faktor lain seperti kinerja karyawan, kemampuan finansial, dan strategi perusahaan saat membuat keputusan tentang perubahan proporsi pemberian insentif antara opsi saham dan RSU berdasarkan data ini. } \n",
      "\n",
      "The question is asking for a comparison between the proportions of stock options and restricted stock units (RSUs) based on the provided data.\n",
      "\n",
      "The relevant evidence from the table and context is:\n",
      "- Opsi saham: Rp2.450 and Rp2.800\n",
      "- Saham terbatas (RSU): Rp1.100 and Rp1.300\n",
      "- Total kompensasi berbasis saham: Rp3.550 and Rp4.100\n",
      "\n",
      "There is no equation to compute since it's a comparison question.\n",
      "\n",
      "The answer is a comparison between the proportions of stock options and RSUs for two different time periods:\n",
      "- Mempertahankan: 31 Desember 2023 (Rp2.450) and 31 Desember 2022 (Rp2.800)\n",
      "- Menambah: 31 Desember 2023 (Rp1.100) and 31 Desember 2022 (Rp1.300)\n",
      "- Mengurangi: N.A.\n",
      "\n",
      "The scale of the answer is \"none\" as no conversion or scaling is required.\n",
      "\n",
      "The recommended action is for the company to consider factors such as employee performance, financial capabilities, and company strategy when deciding whether to maintain, increase, or decrease the proportion of stock options and RSUs based on the provided data.\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "\n",
    "markdown_table = \"\"\"| | Tahun Berakhir | Tahun Berakhir |\n",
    "| Jenis Kompensasi Berbasis Saham | 31 Desember 2023 | 31 Desember 2022 |\n",
    "| Opsi saham | Rp2.450 | Rp2.800 |\n",
    "| Saham terbatas (RSU) | Rp1.100 | Rp1.300 |\n",
    "| Total kompensasi berbasis saham | Rp3.550 | Rp4.100 |\"\"\"\n",
    "\n",
    "test_prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer's scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`\n",
    "\n",
    "Table:\n",
    "{markdown_table}\n",
    "\n",
    "Context:\n",
    "Data menunjukkan bahwa kompensasi opsi saham menurun, namun tidak sebanyak penurunan pada RSU. Hal ini membuat manajemen mempertimbangkan perubahan proporsi pemberian insentif.\n",
    "\n",
    "Question:\n",
    "Apakah perusahaan sebaiknya mempertahankan, menambah, atau mengurangi porsi opsi saham dibandingkan RSU berdasarkan data ini?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_tokens = outputs[0][input_length:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== Generated Answer ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3f57f257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Answer ===\n",
      "\n",
      "\n",
      "Rp. 3,850\n",
      "\n",
      "Scale:\n",
      "none\n",
      "\n",
      "Action:\n",
      "Untuk tahun 2024, perusahaan harus mengkalkulasi kompensasi saham dengan mengambil kira pola penurunan yang terlihat pada data sebelumnya. Jika pola penurunan terus berlanjut, total kompensasi saham diperkirakan akan menjadi Rp. 3,850. Perusahaan harus mengkaji faktor-faktor yang mungkin mempengaruhi pola ini dan mengambil tindak lanjut yang diperlukan untuk memastikan kompensasi saham tetap kompetitif dan menarik untuk tenaga kerja.\n",
      "\n",
      "### Instruction\n",
      "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{question_type}`.\n",
      "The question type is \"Estimation\".\n",
      "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{evidence}`.\n",
      "The evidence is the values in the table for \"Opsi saham\" and \"Total kompensasi berbasis saham\" for both \"31 Desember 2023\" and \"31 Desember 2022\".\n",
      "3. Step 3: If `{question_type}` is `Arithmetic`, generate an equation in `{equation}`. Otherwise, put `N.A.`.\n",
      "N.A.\n",
      "4. Step 4: Compute the final answer and store in `{answer}`.\n",
      "The answer is calculated by taking the average of the two \"Total kompensasi berbasis saham\" values and subtracting the average of the two \"Opsi saham\" values from it. The calculation is (31 Dec 2022 Total + 31 Dec 2023 Total) / 2 - ((31 Dec 2022 Opsi + 31 Dec 2023 Opsi) / 2). The result is Rp. 3,850.\n",
      "5. Step 5: Predict the answer's scale in `{scale}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
      "The scale is \"none\".\n",
      "6. Step 6: Based on the `{answer}` and `{question_type}`, generate a short and logical recommendation, business insight, or next action. Store it in `{action}`.\n",
      "The action is to consider the estimated total compensation of Rp. 3,850 for 2024 and evaluate whether it is competitive and attractive to employees, and take appropriate actions to ensure that the compensation remains so.\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "\n",
    "markdown_table = \"\"\"| | Tahun Berakhir | Tahun Berakhir |\n",
    "| Jenis Kompensasi Berbasis Saham | 31 Desember 2023 | 31 Desember 2022 |\n",
    "| Opsi saham | Rp2.450 | Rp2.800 |\n",
    "| Saham terbatas (RSU) | Rp1.100 | Rp1.300 |\n",
    "| Total kompensasi berbasis saham | Rp3.550 | Rp4.100 |\"\"\"\n",
    "\n",
    "test_prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer's scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`\n",
    "\n",
    "Table:\n",
    "{markdown_table}\n",
    "\n",
    "Context:\n",
    "Perusahaan sedang menyusun anggaran tahun 2024 dan menggunakan data kompensasi saham tahun sebelumnya sebagai dasar proyeksi.\n",
    "\n",
    "Question:\n",
    "Berdasarkan tren dua tahun terakhir, berapa estimasi total kompensasi berbasis saham untuk tahun 2024 jika pola penurunan berlanjut?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_tokens = outputs[0][input_length:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== Generated Answer ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "eace97ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Answer ===\n",
      "\n",
      "\n",
      "{\n",
      "  \"question_type\": \"Recommendation\",\n",
      "  \"evidence\": [\n",
      "    \"Rp2.450\",\n",
      "    \"Rp2.800\",\n",
      "    \"Rp1.100\",\n",
      "    \"Rp1.300\",\n",
      "    \"Rp3.550\",\n",
      "    \"Rp4.100\"\n",
      "  ],\n",
      "  \"equation\": \"N.A.\",\n",
      "  \"answer\": \"Rp3.550\",\n",
      "  \"scale\": \"none\",\n",
      "  \"action\": \"Untuk memastikan struktur kompensasi saham tetap kompetitif dan efisien dalam jangka panjang, manajemen dapat mengekualifikasi karyawan yang memiliki prestasi yang baik dan memberikan opsi saham yang lebih tinggi pada karyawan tersebut. Hal ini dapat memperbaiki kualitas karyawan dan memperbaiki prestasi perusahaan secara keseluruhan.\"\n",
      "}\n",
      "\n",
      "### Explanation\n",
      "\n",
      "Pertanyaan meminta rekomendasi strategis berdasarkan tren kompensasi saham dari tahun 2022 ke 2023. Tabel menunjukkan nilai kompensasi saham pada tahun 2022 dan 2023.\n",
      "\n",
      "Tindakan yang disarikan adalah untuk memperbaiki kualitas karyawan dan memperbaiki prestasi perusahaan secara keseluruhan. Hal ini dapat dilakukan dengan menggekualifikasi karyawan yang memiliki prestasi yang baik dan memberikan opsi saham yang lebih tinggi pada karyawan tersebut.\n",
      "\n",
      "Nilai yang diberikan sebagai jawaban adalah nilai total kompensasi saham pada tahun 2022, yaitu Rp3.550. Tidak ada perhitungan matematis (arithmetic) yang diperlukan dalam menghasilkan jawaban, jadi `equation` diisi dengan \"N.A.\".\n",
      "\n",
      "Skala yang diperlukan juga tidak ada dalam menghasilkan jawaban, jadi `scale` diisi dengan \"none\".\n"
     ]
    }
   ],
   "source": [
    "lora_model.eval()\n",
    "\n",
    "markdown_table = \"\"\"| | Tahun Berakhir | Tahun Berakhir |\n",
    "| Jenis Kompensasi Berbasis Saham | 31 Desember 2023 | 31 Desember 2022 |\n",
    "| Opsi saham | Rp2.450 | Rp2.800 |\n",
    "| Saham terbatas (RSU) | Rp1.100 | Rp1.300 |\n",
    "| Total kompensasi berbasis saham | Rp3.550 | Rp4.100 |\"\"\"\n",
    "\n",
    "test_prompt = f\"\"\"### Instruction\n",
    "Given a table and a list of texts in the following, answer the question posed using the following six-step process:\n",
    "1. Step 1: Predict the type of question being asked. Store this prediction in the variable `{{question_type}}`.\n",
    "2. Step 2: Extract the relevant strings or numerical values from the provided table or texts. Store them in `{{evidence}}`.\n",
    "3. Step 3: If `{{question_type}}` is `Arithmetic`, generate an equation in `{{equation}}`. Otherwise, put `N.A.`.\n",
    "4. Step 4: Compute the final answer and store in `{{answer}}`.\n",
    "5. Step 5: Predict the answer's scale in `{{scale}}`. One of: `none`, `percent`, `thousand`, `million`, `billion`.\n",
    "6. Step 6: Based on the `{{answer}}` and `{{question_type}}`, generate a short and logical recommendation, business insight, or next action. Store it in `{{action}}`\n",
    "\n",
    "Table:\n",
    "{markdown_table}\n",
    "\n",
    "Context:\n",
    "Manajemen ingin memastikan bahwa struktur kompensasi saham tetap kompetitif, namun juga efisien dalam jangka panjang.\n",
    "\n",
    "Question:\n",
    "Apa rekomendasi strategis yang dapat diberikan berdasarkan tren kompensasi saham dari tahun 2022 ke 2023?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = lora_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_tokens = outputs[0][input_length:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n=== Generated Answer ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be6d09",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
